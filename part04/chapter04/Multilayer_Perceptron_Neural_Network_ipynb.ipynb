{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multilayer_Perceptron_Neural_Network.ipynb.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CCw1qRHla2z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8be5162-647f-428b-bf75-5d9f434a09a7"
      },
      "source": [
        "# 0. 사용할 패키지 불러오기\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "width = 16\n",
        "height = 16\n",
        "\n",
        "def generate_dataset(samples):\n",
        "    ds_x = []\n",
        "    ds_y = []\n",
        "    for it in range(samples):\n",
        "        num_pt = np.random.randint(0, width * height)\n",
        "        img = generate_image(num_pt)\n",
        "\n",
        "        ds_y.append(num_pt)\n",
        "        ds_x.append(img)\n",
        "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
        "\n",
        "def generate_image(points):\n",
        "    img = np.zeros((width, height))\n",
        "    pts = np.random.random((points, 2))\n",
        "    for ipt in pts:\n",
        "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
        "    return img.reshape(width, height, 1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSaHMBcwmHem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. 데이터셋 생성하기\n",
        "x_train, y_train = generate_dataset(1500)\n",
        "x_val, y_val = generate_dataset(300)\n",
        "x_test, y_test = generate_dataset(100)\n",
        "\n",
        "x_train_1d = x_train.reshape(x_train.shape[0], width * height)\n",
        "x_val_1d = x_val.reshape(x_val.shape[0], width * height)\n",
        "x_test_1d = x_test.reshape(x_test.shape[0], width * height)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhyrzqiWmbPX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(Dense(256, activation='relu', input_dim=width * height))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(256))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6AtIoFtmlRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3. 모델 학습과정 설정하기\n",
        "model.compile(loss='mse', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg2OkCX2mtGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "941e47cd-d714-49fb-9b0d-96ed2163fd43"
      },
      "source": [
        "# 4. 모델 학습시키기\n",
        "hist = model.fit(x_train_1d, y_train, batch_size=32, epochs=1000, validation_data=(x_val_1d, y_val))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1500 samples, validate on 300 samples\n",
            "Epoch 1/1000\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 4370.5389 - val_loss: 379.4338\n",
            "Epoch 2/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 241.0003 - val_loss: 240.8915\n",
            "Epoch 3/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 181.1956 - val_loss: 194.7220\n",
            "Epoch 4/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 134.3279 - val_loss: 173.7171\n",
            "Epoch 5/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 97.2262 - val_loss: 140.2638\n",
            "Epoch 6/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 77.1107 - val_loss: 134.7276\n",
            "Epoch 7/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 60.2442 - val_loss: 124.8217\n",
            "Epoch 8/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 46.2500 - val_loss: 124.3870\n",
            "Epoch 9/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 40.1038 - val_loss: 118.0456\n",
            "Epoch 10/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 28.3870 - val_loss: 117.5378\n",
            "Epoch 11/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 24.7585 - val_loss: 117.0500\n",
            "Epoch 12/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 19.0990 - val_loss: 115.5748\n",
            "Epoch 13/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 17.9781 - val_loss: 119.2702\n",
            "Epoch 14/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 14.9620 - val_loss: 118.3651\n",
            "Epoch 15/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 10.6460 - val_loss: 122.9920\n",
            "Epoch 16/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 9.8105 - val_loss: 119.7604\n",
            "Epoch 17/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 6.8598 - val_loss: 120.0080\n",
            "Epoch 18/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 5.8228 - val_loss: 119.5639\n",
            "Epoch 19/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 8.1312 - val_loss: 122.4472\n",
            "Epoch 20/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 4.6003 - val_loss: 120.5451\n",
            "Epoch 21/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 3.2657 - val_loss: 121.4867\n",
            "Epoch 22/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 2.0967 - val_loss: 118.3867\n",
            "Epoch 23/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 3.0181 - val_loss: 119.2889\n",
            "Epoch 24/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 2.8705 - val_loss: 120.0312\n",
            "Epoch 25/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 1.7010 - val_loss: 120.9956\n",
            "Epoch 26/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 1.2306 - val_loss: 121.7396\n",
            "Epoch 27/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 1.2111 - val_loss: 120.5115\n",
            "Epoch 28/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.6849 - val_loss: 120.3640\n",
            "Epoch 29/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.5715 - val_loss: 120.7916\n",
            "Epoch 30/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.4303 - val_loss: 120.7054\n",
            "Epoch 31/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.5477 - val_loss: 121.1929\n",
            "Epoch 32/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.4404 - val_loss: 120.5313\n",
            "Epoch 33/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 1.0585 - val_loss: 121.1461\n",
            "Epoch 34/1000\n",
            "1500/1500 [==============================] - 0s 129us/step - loss: 1.4374 - val_loss: 121.8307\n",
            "Epoch 35/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.9871 - val_loss: 121.1454\n",
            "Epoch 36/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.9852 - val_loss: 123.5508\n",
            "Epoch 37/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 1.2912 - val_loss: 119.4538\n",
            "Epoch 38/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 2.3824 - val_loss: 126.5557\n",
            "Epoch 39/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 4.8228 - val_loss: 124.9273\n",
            "Epoch 40/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 5.0770 - val_loss: 121.4702\n",
            "Epoch 41/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 4.0431 - val_loss: 139.5985\n",
            "Epoch 42/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 9.9188 - val_loss: 133.5785\n",
            "Epoch 43/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 3.7881 - val_loss: 125.6622\n",
            "Epoch 44/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 3.3012 - val_loss: 120.6110\n",
            "Epoch 45/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 2.1255 - val_loss: 123.7947\n",
            "Epoch 46/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 1.3543 - val_loss: 119.3044\n",
            "Epoch 47/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 1.1936 - val_loss: 119.6145\n",
            "Epoch 48/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 1.1376 - val_loss: 119.3500\n",
            "Epoch 49/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 1.3524 - val_loss: 121.2041\n",
            "Epoch 50/1000\n",
            "1500/1500 [==============================] - 0s 146us/step - loss: 0.6511 - val_loss: 119.6897\n",
            "Epoch 51/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.4683 - val_loss: 121.3278\n",
            "Epoch 52/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.6248 - val_loss: 120.0378\n",
            "Epoch 53/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.7488 - val_loss: 121.5230\n",
            "Epoch 54/1000\n",
            "1500/1500 [==============================] - 0s 148us/step - loss: 3.2573 - val_loss: 116.2459\n",
            "Epoch 55/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 4.3541 - val_loss: 123.3259\n",
            "Epoch 56/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 2.9634 - val_loss: 124.7460\n",
            "Epoch 57/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 5.1780 - val_loss: 133.8465\n",
            "Epoch 58/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 5.2209 - val_loss: 125.8152\n",
            "Epoch 59/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 13.2181 - val_loss: 122.4931\n",
            "Epoch 60/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 7.4308 - val_loss: 128.1516\n",
            "Epoch 61/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 4.0939 - val_loss: 121.7530\n",
            "Epoch 62/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 5.6063 - val_loss: 116.7540\n",
            "Epoch 63/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 4.9330 - val_loss: 121.7276\n",
            "Epoch 64/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 9.8993 - val_loss: 126.4112\n",
            "Epoch 65/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 17.2687 - val_loss: 126.4072\n",
            "Epoch 66/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 15.7456 - val_loss: 133.2775\n",
            "Epoch 67/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 11.9948 - val_loss: 133.9626\n",
            "Epoch 68/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 12.5400 - val_loss: 120.9963\n",
            "Epoch 69/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 6.1014 - val_loss: 123.4037\n",
            "Epoch 70/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 2.7052 - val_loss: 122.5634\n",
            "Epoch 71/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 2.4258 - val_loss: 119.8123\n",
            "Epoch 72/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 2.0263 - val_loss: 123.6769\n",
            "Epoch 73/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 1.1102 - val_loss: 121.5043\n",
            "Epoch 74/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.9008 - val_loss: 119.6018\n",
            "Epoch 75/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 0.8339 - val_loss: 122.2702\n",
            "Epoch 76/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.9575 - val_loss: 123.2188\n",
            "Epoch 77/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 1.3009 - val_loss: 121.6216\n",
            "Epoch 78/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.7350 - val_loss: 120.5450\n",
            "Epoch 79/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 2.5138 - val_loss: 123.0456\n",
            "Epoch 80/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 1.3478 - val_loss: 119.3749\n",
            "Epoch 81/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 1.5855 - val_loss: 118.7935\n",
            "Epoch 82/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.6559 - val_loss: 120.8905\n",
            "Epoch 83/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.4219 - val_loss: 122.0314\n",
            "Epoch 84/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.3114 - val_loss: 120.8651\n",
            "Epoch 85/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.1965 - val_loss: 121.1277\n",
            "Epoch 86/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.3182 - val_loss: 121.0326\n",
            "Epoch 87/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.4052 - val_loss: 122.1401\n",
            "Epoch 88/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.6946 - val_loss: 120.5029\n",
            "Epoch 89/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 1.1542 - val_loss: 121.7345\n",
            "Epoch 90/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 1.2513 - val_loss: 119.5052\n",
            "Epoch 91/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 1.5965 - val_loss: 124.5339\n",
            "Epoch 92/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 1.6377 - val_loss: 124.6451\n",
            "Epoch 93/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 2.2952 - val_loss: 119.9362\n",
            "Epoch 94/1000\n",
            "1500/1500 [==============================] - 0s 145us/step - loss: 2.6281 - val_loss: 119.3614\n",
            "Epoch 95/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 35.7337 - val_loss: 194.7381\n",
            "Epoch 96/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 25.7333 - val_loss: 125.5032\n",
            "Epoch 97/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 17.9912 - val_loss: 128.4539\n",
            "Epoch 98/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 9.2857 - val_loss: 127.7462\n",
            "Epoch 99/1000\n",
            "1500/1500 [==============================] - 0s 151us/step - loss: 6.2020 - val_loss: 117.6546\n",
            "Epoch 100/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 3.5448 - val_loss: 128.1855\n",
            "Epoch 101/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 3.4090 - val_loss: 119.2660\n",
            "Epoch 102/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.9543 - val_loss: 124.9406\n",
            "Epoch 103/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 1.6684 - val_loss: 121.3570\n",
            "Epoch 104/1000\n",
            "1500/1500 [==============================] - 0s 146us/step - loss: 2.0175 - val_loss: 118.4989\n",
            "Epoch 105/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 1.9342 - val_loss: 124.0057\n",
            "Epoch 106/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 1.6969 - val_loss: 115.8650\n",
            "Epoch 107/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 1.6108 - val_loss: 121.6847\n",
            "Epoch 108/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 1.0798 - val_loss: 118.4213\n",
            "Epoch 109/1000\n",
            "1500/1500 [==============================] - 0s 145us/step - loss: 0.4417 - val_loss: 121.9742\n",
            "Epoch 110/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.5223 - val_loss: 119.3485\n",
            "Epoch 111/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.7438 - val_loss: 118.7234\n",
            "Epoch 112/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 1.1962 - val_loss: 118.6493\n",
            "Epoch 113/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 3.9470 - val_loss: 124.3708\n",
            "Epoch 114/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 2.0840 - val_loss: 119.7380\n",
            "Epoch 115/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.9984 - val_loss: 119.5557\n",
            "Epoch 116/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.9822 - val_loss: 120.8642\n",
            "Epoch 117/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.9365 - val_loss: 123.0764\n",
            "Epoch 118/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.7623 - val_loss: 120.1597\n",
            "Epoch 119/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.4668 - val_loss: 119.4815\n",
            "Epoch 120/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.7413 - val_loss: 118.8093\n",
            "Epoch 121/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.7018 - val_loss: 119.2463\n",
            "Epoch 122/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.5012 - val_loss: 119.4748\n",
            "Epoch 123/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.3692 - val_loss: 119.5355\n",
            "Epoch 124/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.7544 - val_loss: 119.1362\n",
            "Epoch 125/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.9295 - val_loss: 117.7914\n",
            "Epoch 126/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.5255 - val_loss: 118.6689\n",
            "Epoch 127/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.3634 - val_loss: 119.3084\n",
            "Epoch 128/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 3.7482 - val_loss: 122.6862\n",
            "Epoch 129/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 4.8230 - val_loss: 119.5218\n",
            "Epoch 130/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 9.1869 - val_loss: 137.7024\n",
            "Epoch 131/1000\n",
            "1500/1500 [==============================] - 0s 129us/step - loss: 11.4893 - val_loss: 126.4226\n",
            "Epoch 132/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 11.2871 - val_loss: 128.0155\n",
            "Epoch 133/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 7.7030 - val_loss: 125.1956\n",
            "Epoch 134/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 7.7953 - val_loss: 124.6837\n",
            "Epoch 135/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 5.3231 - val_loss: 125.7479\n",
            "Epoch 136/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 6.2518 - val_loss: 127.3532\n",
            "Epoch 137/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 9.2215 - val_loss: 122.1337\n",
            "Epoch 138/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 3.5682 - val_loss: 119.5828\n",
            "Epoch 139/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 3.5595 - val_loss: 121.4932\n",
            "Epoch 140/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 2.2183 - val_loss: 117.8096\n",
            "Epoch 141/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 2.0236 - val_loss: 118.2350\n",
            "Epoch 142/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 5.6608 - val_loss: 139.7739\n",
            "Epoch 143/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 4.2011 - val_loss: 118.3492\n",
            "Epoch 144/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 1.4824 - val_loss: 123.2127\n",
            "Epoch 145/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 3.2569 - val_loss: 124.4646\n",
            "Epoch 146/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 3.7267 - val_loss: 122.2624\n",
            "Epoch 147/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 1.9047 - val_loss: 119.3951\n",
            "Epoch 148/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 3.1048 - val_loss: 119.6771\n",
            "Epoch 149/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 1.5751 - val_loss: 118.6557\n",
            "Epoch 150/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 1.1073 - val_loss: 122.8113\n",
            "Epoch 151/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.8798 - val_loss: 117.8497\n",
            "Epoch 152/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 1.3373 - val_loss: 118.4995\n",
            "Epoch 153/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.5173 - val_loss: 121.1897\n",
            "Epoch 154/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.3894 - val_loss: 119.7239\n",
            "Epoch 155/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.2894 - val_loss: 118.2459\n",
            "Epoch 156/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.4878 - val_loss: 117.7592\n",
            "Epoch 157/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.3835 - val_loss: 117.2287\n",
            "Epoch 158/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.3322 - val_loss: 117.6932\n",
            "Epoch 159/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.2071 - val_loss: 120.1150\n",
            "Epoch 160/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.4632 - val_loss: 119.3602\n",
            "Epoch 161/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.2941 - val_loss: 118.7166\n",
            "Epoch 162/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1808 - val_loss: 118.4590\n",
            "Epoch 163/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.4506 - val_loss: 118.0248\n",
            "Epoch 164/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 1.3280 - val_loss: 121.9264\n",
            "Epoch 165/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 6.7421 - val_loss: 157.2026\n",
            "Epoch 166/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 33.7738 - val_loss: 125.2088\n",
            "Epoch 167/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 17.3605 - val_loss: 118.8308\n",
            "Epoch 168/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 4.9933 - val_loss: 120.2014\n",
            "Epoch 169/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 2.0058 - val_loss: 120.5938\n",
            "Epoch 170/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 1.3083 - val_loss: 120.2647\n",
            "Epoch 171/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 1.0820 - val_loss: 118.6596\n",
            "Epoch 172/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.6282 - val_loss: 118.9032\n",
            "Epoch 173/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.5685 - val_loss: 119.2722\n",
            "Epoch 174/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.3974 - val_loss: 120.6190\n",
            "Epoch 175/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.3942 - val_loss: 118.8361\n",
            "Epoch 176/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.6242 - val_loss: 119.3037\n",
            "Epoch 177/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 3.0026 - val_loss: 121.8669\n",
            "Epoch 178/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 3.0901 - val_loss: 120.9461\n",
            "Epoch 179/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 1.1656 - val_loss: 120.5140\n",
            "Epoch 180/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.7455 - val_loss: 118.4053\n",
            "Epoch 181/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.5813 - val_loss: 117.6681\n",
            "Epoch 182/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 0.3505 - val_loss: 117.4030\n",
            "Epoch 183/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.3190 - val_loss: 117.6501\n",
            "Epoch 184/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.3000 - val_loss: 119.0169\n",
            "Epoch 185/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.3264 - val_loss: 119.8228\n",
            "Epoch 186/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.2492 - val_loss: 119.8863\n",
            "Epoch 187/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 0.2282 - val_loss: 118.1804\n",
            "Epoch 188/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 0.9751 - val_loss: 116.5388\n",
            "Epoch 189/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 1.0032 - val_loss: 121.8564\n",
            "Epoch 190/1000\n",
            "1500/1500 [==============================] - 0s 129us/step - loss: 3.2572 - val_loss: 117.5770\n",
            "Epoch 191/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 2.3443 - val_loss: 120.0322\n",
            "Epoch 192/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 3.0367 - val_loss: 119.3639\n",
            "Epoch 193/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 4.2872 - val_loss: 120.0704\n",
            "Epoch 194/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 5.0867 - val_loss: 120.2166\n",
            "Epoch 195/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 3.9124 - val_loss: 122.3895\n",
            "Epoch 196/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 2.1842 - val_loss: 118.3082\n",
            "Epoch 197/1000\n",
            "1500/1500 [==============================] - 0s 151us/step - loss: 1.9936 - val_loss: 124.7267\n",
            "Epoch 198/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 5.7915 - val_loss: 122.2818\n",
            "Epoch 199/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 3.3736 - val_loss: 125.1018\n",
            "Epoch 200/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 3.8204 - val_loss: 121.0373\n",
            "Epoch 201/1000\n",
            "1500/1500 [==============================] - 0s 144us/step - loss: 1.4579 - val_loss: 118.4931\n",
            "Epoch 202/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 1.1592 - val_loss: 120.1253\n",
            "Epoch 203/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 1.4323 - val_loss: 119.5988\n",
            "Epoch 204/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.6048 - val_loss: 122.0250\n",
            "Epoch 205/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.8126 - val_loss: 119.8618\n",
            "Epoch 206/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 0.4224 - val_loss: 118.3062\n",
            "Epoch 207/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 1.2012 - val_loss: 117.7658\n",
            "Epoch 208/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 5.5668 - val_loss: 123.8448\n",
            "Epoch 209/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 4.6089 - val_loss: 114.9118\n",
            "Epoch 210/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 2.9221 - val_loss: 122.6209\n",
            "Epoch 211/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 1.1994 - val_loss: 117.8008\n",
            "Epoch 212/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.6990 - val_loss: 118.0337\n",
            "Epoch 213/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 0.7089 - val_loss: 118.0975\n",
            "Epoch 214/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.5569 - val_loss: 117.0138\n",
            "Epoch 215/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.5064 - val_loss: 118.6096\n",
            "Epoch 216/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.4085 - val_loss: 118.2666\n",
            "Epoch 217/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.5716 - val_loss: 117.6391\n",
            "Epoch 218/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.3756 - val_loss: 119.1318\n",
            "Epoch 219/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.3683 - val_loss: 117.7453\n",
            "Epoch 220/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.4166 - val_loss: 118.1702\n",
            "Epoch 221/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.5161 - val_loss: 118.1272\n",
            "Epoch 222/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.7646 - val_loss: 119.9813\n",
            "Epoch 223/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 1.3906 - val_loss: 117.4774\n",
            "Epoch 224/1000\n",
            "1500/1500 [==============================] - 0s 144us/step - loss: 1.2735 - val_loss: 120.7506\n",
            "Epoch 225/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 1.4722 - val_loss: 116.2870\n",
            "Epoch 226/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 4.4273 - val_loss: 129.4285\n",
            "Epoch 227/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 16.5215 - val_loss: 116.9837\n",
            "Epoch 228/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 8.4649 - val_loss: 116.2732\n",
            "Epoch 229/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 5.5839 - val_loss: 122.8145\n",
            "Epoch 230/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 4.4879 - val_loss: 120.4632\n",
            "Epoch 231/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 2.3096 - val_loss: 118.2162\n",
            "Epoch 232/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 4.8643 - val_loss: 131.4485\n",
            "Epoch 233/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 6.3253 - val_loss: 122.6696\n",
            "Epoch 234/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 3.7457 - val_loss: 118.4801\n",
            "Epoch 235/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 2.1013 - val_loss: 119.7460\n",
            "Epoch 236/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 2.1194 - val_loss: 129.0747\n",
            "Epoch 237/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 2.9228 - val_loss: 118.8478\n",
            "Epoch 238/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.9580 - val_loss: 118.1676\n",
            "Epoch 239/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 1.4928 - val_loss: 117.3721\n",
            "Epoch 240/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 1.5025 - val_loss: 117.3482\n",
            "Epoch 241/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.6728 - val_loss: 117.4590\n",
            "Epoch 242/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.3744 - val_loss: 118.0386\n",
            "Epoch 243/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.7973 - val_loss: 118.4771\n",
            "Epoch 244/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.8057 - val_loss: 119.6554\n",
            "Epoch 245/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.5283 - val_loss: 118.4006\n",
            "Epoch 246/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.2943 - val_loss: 117.5341\n",
            "Epoch 247/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.4032 - val_loss: 119.2257\n",
            "Epoch 248/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 1.0675 - val_loss: 119.7318\n",
            "Epoch 249/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 1.1464 - val_loss: 115.0552\n",
            "Epoch 250/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.1538 - val_loss: 116.4510\n",
            "Epoch 251/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.9887 - val_loss: 116.7956\n",
            "Epoch 252/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.6078 - val_loss: 118.0627\n",
            "Epoch 253/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.4191 - val_loss: 116.6920\n",
            "Epoch 254/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.3226 - val_loss: 121.2385\n",
            "Epoch 255/1000\n",
            "1500/1500 [==============================] - 0s 150us/step - loss: 2.0374 - val_loss: 125.1216\n",
            "Epoch 256/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 4.4200 - val_loss: 120.0496\n",
            "Epoch 257/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 2.7965 - val_loss: 118.0510\n",
            "Epoch 258/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 1.5301 - val_loss: 117.2356\n",
            "Epoch 259/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 3.3399 - val_loss: 117.3824\n",
            "Epoch 260/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 13.2538 - val_loss: 118.0948\n",
            "Epoch 261/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 5.2214 - val_loss: 119.7049\n",
            "Epoch 262/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 1.8747 - val_loss: 117.2013\n",
            "Epoch 263/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 2.3062 - val_loss: 119.8162\n",
            "Epoch 264/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.1556 - val_loss: 119.4067\n",
            "Epoch 265/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 1.7281 - val_loss: 117.3673\n",
            "Epoch 266/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 1.1510 - val_loss: 116.4036\n",
            "Epoch 267/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 0.4348 - val_loss: 119.0606\n",
            "Epoch 268/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 0.6236 - val_loss: 117.1820\n",
            "Epoch 269/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.4294 - val_loss: 119.0464\n",
            "Epoch 270/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.1976 - val_loss: 117.7162\n",
            "Epoch 271/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.1546 - val_loss: 119.0310\n",
            "Epoch 272/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.2662 - val_loss: 118.2187\n",
            "Epoch 273/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.1941 - val_loss: 117.9525\n",
            "Epoch 274/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 0.2153 - val_loss: 116.9835\n",
            "Epoch 275/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.1799 - val_loss: 117.6184\n",
            "Epoch 276/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.1873 - val_loss: 118.8254\n",
            "Epoch 277/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.8012 - val_loss: 116.2906\n",
            "Epoch 278/1000\n",
            "1500/1500 [==============================] - 0s 152us/step - loss: 0.8983 - val_loss: 118.3815\n",
            "Epoch 279/1000\n",
            "1500/1500 [==============================] - 0s 145us/step - loss: 1.2576 - val_loss: 120.6266\n",
            "Epoch 280/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 3.6777 - val_loss: 117.9122\n",
            "Epoch 281/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 3.6591 - val_loss: 119.7725\n",
            "Epoch 282/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 2.2950 - val_loss: 116.8417\n",
            "Epoch 283/1000\n",
            "1500/1500 [==============================] - 0s 145us/step - loss: 3.4675 - val_loss: 117.9029\n",
            "Epoch 284/1000\n",
            "1500/1500 [==============================] - 0s 145us/step - loss: 1.4786 - val_loss: 119.0317\n",
            "Epoch 285/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 2.6422 - val_loss: 127.8416\n",
            "Epoch 286/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 6.2443 - val_loss: 119.3870\n",
            "Epoch 287/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 3.7050 - val_loss: 120.6202\n",
            "Epoch 288/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 2.8981 - val_loss: 118.7599\n",
            "Epoch 289/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 2.0752 - val_loss: 119.6930\n",
            "Epoch 290/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 1.2429 - val_loss: 121.1132\n",
            "Epoch 291/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.8536 - val_loss: 116.3641\n",
            "Epoch 292/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.4093 - val_loss: 116.1871\n",
            "Epoch 293/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.3995 - val_loss: 116.7876\n",
            "Epoch 294/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.4207 - val_loss: 119.2410\n",
            "Epoch 295/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 1.1965 - val_loss: 121.3818\n",
            "Epoch 296/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.2804 - val_loss: 118.9965\n",
            "Epoch 297/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 1.9681 - val_loss: 116.7025\n",
            "Epoch 298/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 2.0976 - val_loss: 118.9051\n",
            "Epoch 299/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 2.6517 - val_loss: 120.5504\n",
            "Epoch 300/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 2.3339 - val_loss: 118.2581\n",
            "Epoch 301/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 2.7413 - val_loss: 121.2763\n",
            "Epoch 302/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 2.5106 - val_loss: 118.6784\n",
            "Epoch 303/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 1.0374 - val_loss: 116.9270\n",
            "Epoch 304/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 2.1077 - val_loss: 117.6055\n",
            "Epoch 305/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 2.8922 - val_loss: 119.4293\n",
            "Epoch 306/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 22.3935 - val_loss: 116.4728\n",
            "Epoch 307/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 17.6114 - val_loss: 119.6927\n",
            "Epoch 308/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 3.2199 - val_loss: 113.9814\n",
            "Epoch 309/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 1.4528 - val_loss: 117.1009\n",
            "Epoch 310/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.6263 - val_loss: 115.4541\n",
            "Epoch 311/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 0.5207 - val_loss: 115.1927\n",
            "Epoch 312/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.2772 - val_loss: 116.9513\n",
            "Epoch 313/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.2562 - val_loss: 116.4647\n",
            "Epoch 314/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.2136 - val_loss: 114.9788\n",
            "Epoch 315/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.2948 - val_loss: 116.4900\n",
            "Epoch 316/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1482 - val_loss: 116.6770\n",
            "Epoch 317/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 0.2052 - val_loss: 115.5899\n",
            "Epoch 318/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.1312 - val_loss: 115.9977\n",
            "Epoch 319/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.0573 - val_loss: 116.4309\n",
            "Epoch 320/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.0420 - val_loss: 115.9533\n",
            "Epoch 321/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.0492 - val_loss: 116.4594\n",
            "Epoch 322/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.0259 - val_loss: 116.4825\n",
            "Epoch 323/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.0267 - val_loss: 116.0837\n",
            "Epoch 324/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.0230 - val_loss: 116.2329\n",
            "Epoch 325/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.0203 - val_loss: 116.1199\n",
            "Epoch 326/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.0138 - val_loss: 116.4066\n",
            "Epoch 327/1000\n",
            "1500/1500 [==============================] - 0s 151us/step - loss: 0.0134 - val_loss: 116.1569\n",
            "Epoch 328/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.0244 - val_loss: 116.1197\n",
            "Epoch 329/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.0354 - val_loss: 116.4139\n",
            "Epoch 330/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.0359 - val_loss: 116.7189\n",
            "Epoch 331/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.0658 - val_loss: 115.9020\n",
            "Epoch 332/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 0.3120 - val_loss: 115.9924\n",
            "Epoch 333/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 1.2205 - val_loss: 115.5719\n",
            "Epoch 334/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 1.3826 - val_loss: 116.8857\n",
            "Epoch 335/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 2.5995 - val_loss: 117.5168\n",
            "Epoch 336/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 6.0889 - val_loss: 114.6684\n",
            "Epoch 337/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 3.6839 - val_loss: 119.3055\n",
            "Epoch 338/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 11.3675 - val_loss: 117.1620\n",
            "Epoch 339/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 12.1532 - val_loss: 116.5056\n",
            "Epoch 340/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 6.5648 - val_loss: 122.5293\n",
            "Epoch 341/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 5.9479 - val_loss: 116.6894\n",
            "Epoch 342/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 2.2812 - val_loss: 114.7941\n",
            "Epoch 343/1000\n",
            "1500/1500 [==============================] - 0s 150us/step - loss: 2.5967 - val_loss: 119.6899\n",
            "Epoch 344/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 2.0804 - val_loss: 120.4927\n",
            "Epoch 345/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 1.1313 - val_loss: 116.4052\n",
            "Epoch 346/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.5566 - val_loss: 117.2357\n",
            "Epoch 347/1000\n",
            "1500/1500 [==============================] - 0s 146us/step - loss: 0.4671 - val_loss: 117.5475\n",
            "Epoch 348/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.3099 - val_loss: 116.8101\n",
            "Epoch 349/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.1956 - val_loss: 116.9274\n",
            "Epoch 350/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.1131 - val_loss: 116.4442\n",
            "Epoch 351/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.0799 - val_loss: 116.5694\n",
            "Epoch 352/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.1090 - val_loss: 116.7447\n",
            "Epoch 353/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.0830 - val_loss: 116.7619\n",
            "Epoch 354/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.0934 - val_loss: 116.5944\n",
            "Epoch 355/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.0767 - val_loss: 116.9277\n",
            "Epoch 356/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.0559 - val_loss: 117.2861\n",
            "Epoch 357/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 0.0938 - val_loss: 115.6796\n",
            "Epoch 358/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.3067 - val_loss: 118.3136\n",
            "Epoch 359/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.2578 - val_loss: 118.4480\n",
            "Epoch 360/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1852 - val_loss: 116.9378\n",
            "Epoch 361/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.1165 - val_loss: 116.9516\n",
            "Epoch 362/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.3196 - val_loss: 116.6970\n",
            "Epoch 363/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.5734 - val_loss: 118.6396\n",
            "Epoch 364/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.8684 - val_loss: 116.5261\n",
            "Epoch 365/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.3783 - val_loss: 116.3168\n",
            "Epoch 366/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 1.5333 - val_loss: 117.8915\n",
            "Epoch 367/1000\n",
            "1500/1500 [==============================] - 0s 146us/step - loss: 0.6858 - val_loss: 117.7620\n",
            "Epoch 368/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.6395 - val_loss: 118.4049\n",
            "Epoch 369/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 2.5019 - val_loss: 113.9253\n",
            "Epoch 370/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 2.2527 - val_loss: 116.5244\n",
            "Epoch 371/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 1.8276 - val_loss: 119.5989\n",
            "Epoch 372/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 11.3816 - val_loss: 130.8238\n",
            "Epoch 373/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 7.1586 - val_loss: 120.7874\n",
            "Epoch 374/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 2.1184 - val_loss: 118.8177\n",
            "Epoch 375/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 1.1271 - val_loss: 118.9317\n",
            "Epoch 376/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.5548 - val_loss: 116.2069\n",
            "Epoch 377/1000\n",
            "1500/1500 [==============================] - 0s 144us/step - loss: 0.6758 - val_loss: 118.5756\n",
            "Epoch 378/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.6475 - val_loss: 116.0865\n",
            "Epoch 379/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.3883 - val_loss: 117.2514\n",
            "Epoch 380/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.2780 - val_loss: 117.0976\n",
            "Epoch 381/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.2355 - val_loss: 117.4784\n",
            "Epoch 382/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.2206 - val_loss: 116.1712\n",
            "Epoch 383/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.3558 - val_loss: 118.3993\n",
            "Epoch 384/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.1876 - val_loss: 117.4732\n",
            "Epoch 385/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.2502 - val_loss: 117.0690\n",
            "Epoch 386/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.3248 - val_loss: 117.5935\n",
            "Epoch 387/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.2102 - val_loss: 116.6275\n",
            "Epoch 388/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.4802 - val_loss: 116.7464\n",
            "Epoch 389/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.8280 - val_loss: 116.2620\n",
            "Epoch 390/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.7221 - val_loss: 116.9885\n",
            "Epoch 391/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.4767 - val_loss: 118.7753\n",
            "Epoch 392/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.4319 - val_loss: 116.6336\n",
            "Epoch 393/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.5581 - val_loss: 116.2855\n",
            "Epoch 394/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.4875 - val_loss: 115.7314\n",
            "Epoch 395/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.7010 - val_loss: 116.4392\n",
            "Epoch 396/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.6913 - val_loss: 116.4507\n",
            "Epoch 397/1000\n",
            "1500/1500 [==============================] - 0s 146us/step - loss: 1.1639 - val_loss: 118.0147\n",
            "Epoch 398/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 4.4419 - val_loss: 116.6933\n",
            "Epoch 399/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 13.1594 - val_loss: 127.2669\n",
            "Epoch 400/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 4.5021 - val_loss: 121.0685\n",
            "Epoch 401/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 2.2675 - val_loss: 116.1532\n",
            "Epoch 402/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 2.6714 - val_loss: 116.5639\n",
            "Epoch 403/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.3462 - val_loss: 115.0363\n",
            "Epoch 404/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.9130 - val_loss: 118.9027\n",
            "Epoch 405/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.5522 - val_loss: 116.4079\n",
            "Epoch 406/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.7371 - val_loss: 115.1274\n",
            "Epoch 407/1000\n",
            "1500/1500 [==============================] - 0s 146us/step - loss: 0.5560 - val_loss: 114.9570\n",
            "Epoch 408/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.4236 - val_loss: 116.4281\n",
            "Epoch 409/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.2066 - val_loss: 116.3000\n",
            "Epoch 410/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.2371 - val_loss: 117.9123\n",
            "Epoch 411/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 2.0072 - val_loss: 121.1972\n",
            "Epoch 412/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 2.2248 - val_loss: 117.0154\n",
            "Epoch 413/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 1.2802 - val_loss: 118.1899\n",
            "Epoch 414/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.8318 - val_loss: 118.6743\n",
            "Epoch 415/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.9483 - val_loss: 115.1078\n",
            "Epoch 416/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.6822 - val_loss: 117.6270\n",
            "Epoch 417/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.4137 - val_loss: 116.6906\n",
            "Epoch 418/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.3404 - val_loss: 116.2785\n",
            "Epoch 419/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.7422 - val_loss: 118.1775\n",
            "Epoch 420/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 1.7557 - val_loss: 118.0949\n",
            "Epoch 421/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.8054 - val_loss: 118.3551\n",
            "Epoch 422/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.8992 - val_loss: 117.8173\n",
            "Epoch 423/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.6345 - val_loss: 115.1900\n",
            "Epoch 424/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.7417 - val_loss: 117.3338\n",
            "Epoch 425/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.6189 - val_loss: 114.0331\n",
            "Epoch 426/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.5549 - val_loss: 115.0450\n",
            "Epoch 427/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.6184 - val_loss: 115.1298\n",
            "Epoch 428/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.4624 - val_loss: 116.8089\n",
            "Epoch 429/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.3193 - val_loss: 117.0413\n",
            "Epoch 430/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.2830 - val_loss: 116.5429\n",
            "Epoch 431/1000\n",
            "1500/1500 [==============================] - 0s 149us/step - loss: 0.1902 - val_loss: 115.1684\n",
            "Epoch 432/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 1.9938 - val_loss: 120.3381\n",
            "Epoch 433/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 3.9071 - val_loss: 114.8039\n",
            "Epoch 434/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 3.0639 - val_loss: 116.1967\n",
            "Epoch 435/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 5.2468 - val_loss: 117.3673\n",
            "Epoch 436/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 6.3471 - val_loss: 128.1750\n",
            "Epoch 437/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 6.0236 - val_loss: 119.3368\n",
            "Epoch 438/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 4.7124 - val_loss: 115.6550\n",
            "Epoch 439/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 2.4487 - val_loss: 116.9217\n",
            "Epoch 440/1000\n",
            "1500/1500 [==============================] - 0s 129us/step - loss: 1.2594 - val_loss: 118.0782\n",
            "Epoch 441/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.9411 - val_loss: 118.6947\n",
            "Epoch 442/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.5241 - val_loss: 115.0260\n",
            "Epoch 443/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.3563 - val_loss: 115.7287\n",
            "Epoch 444/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.4939 - val_loss: 114.9771\n",
            "Epoch 445/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.3246 - val_loss: 114.4942\n",
            "Epoch 446/1000\n",
            "1500/1500 [==============================] - 0s 147us/step - loss: 0.2574 - val_loss: 115.1330\n",
            "Epoch 447/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.2261 - val_loss: 116.4594\n",
            "Epoch 448/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1971 - val_loss: 115.9098\n",
            "Epoch 449/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.1090 - val_loss: 116.0729\n",
            "Epoch 450/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.0537 - val_loss: 115.5246\n",
            "Epoch 451/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.0288 - val_loss: 115.9166\n",
            "Epoch 452/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.0682 - val_loss: 115.4721\n",
            "Epoch 453/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.1282 - val_loss: 115.3375\n",
            "Epoch 454/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.1154 - val_loss: 116.7728\n",
            "Epoch 455/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.1104 - val_loss: 116.5229\n",
            "Epoch 456/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.0801 - val_loss: 116.5480\n",
            "Epoch 457/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.1555 - val_loss: 116.1971\n",
            "Epoch 458/1000\n",
            "1500/1500 [==============================] - 0s 144us/step - loss: 0.1101 - val_loss: 115.9324\n",
            "Epoch 459/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.1988 - val_loss: 115.0967\n",
            "Epoch 460/1000\n",
            "1500/1500 [==============================] - 0s 129us/step - loss: 1.1865 - val_loss: 115.5164\n",
            "Epoch 461/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 1.1563 - val_loss: 121.7495\n",
            "Epoch 462/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 6.4332 - val_loss: 116.9481\n",
            "Epoch 463/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 2.7999 - val_loss: 117.4496\n",
            "Epoch 464/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 2.6509 - val_loss: 114.3898\n",
            "Epoch 465/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.9573 - val_loss: 119.7450\n",
            "Epoch 466/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 6.1468 - val_loss: 141.6808\n",
            "Epoch 467/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 15.9123 - val_loss: 116.6603\n",
            "Epoch 468/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 4.3145 - val_loss: 119.2878\n",
            "Epoch 469/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 1.7442 - val_loss: 115.7507\n",
            "Epoch 470/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.9981 - val_loss: 117.4466\n",
            "Epoch 471/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.7049 - val_loss: 119.1419\n",
            "Epoch 472/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.5005 - val_loss: 117.5403\n",
            "Epoch 473/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.5962 - val_loss: 116.4113\n",
            "Epoch 474/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.2066 - val_loss: 117.2327\n",
            "Epoch 475/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.1074 - val_loss: 116.5871\n",
            "Epoch 476/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.0817 - val_loss: 117.0277\n",
            "Epoch 477/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.0579 - val_loss: 116.8851\n",
            "Epoch 478/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.0813 - val_loss: 117.1841\n",
            "Epoch 479/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.0480 - val_loss: 116.8389\n",
            "Epoch 480/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.0702 - val_loss: 116.6979\n",
            "Epoch 481/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.0924 - val_loss: 116.4122\n",
            "Epoch 482/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.0468 - val_loss: 116.8082\n",
            "Epoch 483/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.0299 - val_loss: 117.4102\n",
            "Epoch 484/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.0241 - val_loss: 116.9833\n",
            "Epoch 485/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.0204 - val_loss: 117.2564\n",
            "Epoch 486/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.0504 - val_loss: 116.1541\n",
            "Epoch 487/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.1283 - val_loss: 116.6529\n",
            "Epoch 488/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1312 - val_loss: 119.1749\n",
            "Epoch 489/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 0.5317 - val_loss: 116.3768\n",
            "Epoch 490/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.4513 - val_loss: 116.3534\n",
            "Epoch 491/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.9165 - val_loss: 116.3464\n",
            "Epoch 492/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 1.9781 - val_loss: 116.4520\n",
            "Epoch 493/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 3.2263 - val_loss: 132.2981\n",
            "Epoch 494/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 5.6934 - val_loss: 118.5450\n",
            "Epoch 495/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 8.7419 - val_loss: 119.8070\n",
            "Epoch 496/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 3.4605 - val_loss: 124.1870\n",
            "Epoch 497/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 2.8604 - val_loss: 120.2218\n",
            "Epoch 498/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 1.2622 - val_loss: 116.2637\n",
            "Epoch 499/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.6870 - val_loss: 116.3155\n",
            "Epoch 500/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.6113 - val_loss: 116.0264\n",
            "Epoch 501/1000\n",
            "1500/1500 [==============================] - 0s 145us/step - loss: 0.3070 - val_loss: 116.6453\n",
            "Epoch 502/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.1472 - val_loss: 116.3989\n",
            "Epoch 503/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.0693 - val_loss: 116.2709\n",
            "Epoch 504/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.0806 - val_loss: 116.0930\n",
            "Epoch 505/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.0734 - val_loss: 116.3846\n",
            "Epoch 506/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.0658 - val_loss: 116.2813\n",
            "Epoch 507/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.0508 - val_loss: 116.1256\n",
            "Epoch 508/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.0430 - val_loss: 116.2636\n",
            "Epoch 509/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.0423 - val_loss: 116.0530\n",
            "Epoch 510/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.0413 - val_loss: 116.2458\n",
            "Epoch 511/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.0469 - val_loss: 116.0052\n",
            "Epoch 512/1000\n",
            "1500/1500 [==============================] - 0s 145us/step - loss: 0.0437 - val_loss: 115.7751\n",
            "Epoch 513/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.0405 - val_loss: 116.4490\n",
            "Epoch 514/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.0525 - val_loss: 116.7863\n",
            "Epoch 515/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.0940 - val_loss: 115.2436\n",
            "Epoch 516/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.2452 - val_loss: 116.1001\n",
            "Epoch 517/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.2938 - val_loss: 117.3369\n",
            "Epoch 518/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.2755 - val_loss: 114.9601\n",
            "Epoch 519/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 0.4465 - val_loss: 117.6327\n",
            "Epoch 520/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 4.8187 - val_loss: 115.8229\n",
            "Epoch 521/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 2.7776 - val_loss: 118.0814\n",
            "Epoch 522/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 1.6575 - val_loss: 116.2775\n",
            "Epoch 523/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 1.4484 - val_loss: 117.4668\n",
            "Epoch 524/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 3.6563 - val_loss: 116.1680\n",
            "Epoch 525/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 2.1683 - val_loss: 120.6487\n",
            "Epoch 526/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 1.4789 - val_loss: 114.6203\n",
            "Epoch 527/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.9666 - val_loss: 118.0812\n",
            "Epoch 528/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 1.8201 - val_loss: 117.4148\n",
            "Epoch 529/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.6319 - val_loss: 115.3494\n",
            "Epoch 530/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 1.1242 - val_loss: 121.0456\n",
            "Epoch 531/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.9911 - val_loss: 115.0184\n",
            "Epoch 532/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.3519 - val_loss: 114.0375\n",
            "Epoch 533/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.4476 - val_loss: 113.6257\n",
            "Epoch 534/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.2561 - val_loss: 114.9059\n",
            "Epoch 535/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.1462 - val_loss: 114.5178\n",
            "Epoch 536/1000\n",
            "1500/1500 [==============================] - 0s 144us/step - loss: 0.1619 - val_loss: 114.4436\n",
            "Epoch 537/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.1182 - val_loss: 114.9332\n",
            "Epoch 538/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.1015 - val_loss: 115.3729\n",
            "Epoch 539/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.0818 - val_loss: 114.7030\n",
            "Epoch 540/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.0714 - val_loss: 114.1230\n",
            "Epoch 541/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.0648 - val_loss: 114.5386\n",
            "Epoch 542/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.0579 - val_loss: 115.0585\n",
            "Epoch 543/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1070 - val_loss: 113.7407\n",
            "Epoch 544/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.0983 - val_loss: 114.2581\n",
            "Epoch 545/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.1152 - val_loss: 114.1495\n",
            "Epoch 546/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.9605 - val_loss: 115.5418\n",
            "Epoch 547/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 2.0399 - val_loss: 114.3501\n",
            "Epoch 548/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.9229 - val_loss: 114.1250\n",
            "Epoch 549/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 1.6266 - val_loss: 114.0809\n",
            "Epoch 550/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 2.1736 - val_loss: 120.8900\n",
            "Epoch 551/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 5.8415 - val_loss: 117.0823\n",
            "Epoch 552/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 2.5749 - val_loss: 116.0255\n",
            "Epoch 553/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 1.3025 - val_loss: 113.5702\n",
            "Epoch 554/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.8331 - val_loss: 113.7057\n",
            "Epoch 555/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.6017 - val_loss: 116.5208\n",
            "Epoch 556/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.5039 - val_loss: 116.6928\n",
            "Epoch 557/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.2875 - val_loss: 114.6607\n",
            "Epoch 558/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.2798 - val_loss: 113.9320\n",
            "Epoch 559/1000\n",
            "1500/1500 [==============================] - 0s 144us/step - loss: 0.2862 - val_loss: 114.1828\n",
            "Epoch 560/1000\n",
            "1500/1500 [==============================] - 0s 149us/step - loss: 0.2406 - val_loss: 114.5792\n",
            "Epoch 561/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.6883 - val_loss: 114.7305\n",
            "Epoch 562/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 3.5555 - val_loss: 115.2668\n",
            "Epoch 563/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 3.2207 - val_loss: 119.2015\n",
            "Epoch 564/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 3.0070 - val_loss: 112.7081\n",
            "Epoch 565/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 2.1371 - val_loss: 114.4625\n",
            "Epoch 566/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 2.0508 - val_loss: 115.9721\n",
            "Epoch 567/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 1.5520 - val_loss: 114.4931\n",
            "Epoch 568/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.9542 - val_loss: 113.9905\n",
            "Epoch 569/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.3843 - val_loss: 114.3941\n",
            "Epoch 570/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.3552 - val_loss: 112.7200\n",
            "Epoch 571/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.3016 - val_loss: 115.0467\n",
            "Epoch 572/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.2045 - val_loss: 114.0642\n",
            "Epoch 573/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.1168 - val_loss: 113.7841\n",
            "Epoch 574/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.1427 - val_loss: 113.8522\n",
            "Epoch 575/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.0871 - val_loss: 113.6627\n",
            "Epoch 576/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.0720 - val_loss: 113.7232\n",
            "Epoch 577/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.0441 - val_loss: 114.4817\n",
            "Epoch 578/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.2546 - val_loss: 112.9591\n",
            "Epoch 579/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.4920 - val_loss: 113.7718\n",
            "Epoch 580/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.4108 - val_loss: 117.5495\n",
            "Epoch 581/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.8862 - val_loss: 115.0392\n",
            "Epoch 582/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 1.2255 - val_loss: 113.6516\n",
            "Epoch 583/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 1.1667 - val_loss: 114.1850\n",
            "Epoch 584/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.6355 - val_loss: 113.2599\n",
            "Epoch 585/1000\n",
            "1500/1500 [==============================] - 0s 147us/step - loss: 0.3816 - val_loss: 113.0882\n",
            "Epoch 586/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.2285 - val_loss: 113.6570\n",
            "Epoch 587/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.3646 - val_loss: 114.4814\n",
            "Epoch 588/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.6689 - val_loss: 117.8416\n",
            "Epoch 589/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 1.1575 - val_loss: 114.8114\n",
            "Epoch 590/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.6173 - val_loss: 112.5540\n",
            "Epoch 591/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.5184 - val_loss: 114.4274\n",
            "Epoch 592/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.5255 - val_loss: 116.9761\n",
            "Epoch 593/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 2.9581 - val_loss: 118.5372\n",
            "Epoch 594/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 3.2275 - val_loss: 114.1608\n",
            "Epoch 595/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 1.9088 - val_loss: 115.6556\n",
            "Epoch 596/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.2100 - val_loss: 113.8584\n",
            "Epoch 597/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.8760 - val_loss: 112.8306\n",
            "Epoch 598/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 3.1133 - val_loss: 114.9020\n",
            "Epoch 599/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 1.7882 - val_loss: 122.0014\n",
            "Epoch 600/1000\n",
            "1500/1500 [==============================] - 0s 144us/step - loss: 1.0746 - val_loss: 114.6190\n",
            "Epoch 601/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.8839 - val_loss: 112.6614\n",
            "Epoch 602/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.4098 - val_loss: 115.8495\n",
            "Epoch 603/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.2609 - val_loss: 112.9119\n",
            "Epoch 604/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.2198 - val_loss: 113.9682\n",
            "Epoch 605/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.2335 - val_loss: 113.6762\n",
            "Epoch 606/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 0.2019 - val_loss: 113.4656\n",
            "Epoch 607/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.3561 - val_loss: 114.2284\n",
            "Epoch 608/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 0.3505 - val_loss: 113.6677\n",
            "Epoch 609/1000\n",
            "1500/1500 [==============================] - 0s 146us/step - loss: 0.2975 - val_loss: 114.4617\n",
            "Epoch 610/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.1306 - val_loss: 114.3228\n",
            "Epoch 611/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.1257 - val_loss: 113.4041\n",
            "Epoch 612/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.1477 - val_loss: 114.5026\n",
            "Epoch 613/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.1838 - val_loss: 114.1350\n",
            "Epoch 614/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.3537 - val_loss: 114.5107\n",
            "Epoch 615/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.3272 - val_loss: 113.3760\n",
            "Epoch 616/1000\n",
            "1500/1500 [==============================] - 0s 127us/step - loss: 0.9505 - val_loss: 116.1063\n",
            "Epoch 617/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 5.8512 - val_loss: 113.4721\n",
            "Epoch 618/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 4.9897 - val_loss: 118.3238\n",
            "Epoch 619/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 3.0870 - val_loss: 116.2025\n",
            "Epoch 620/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 1.5334 - val_loss: 118.7697\n",
            "Epoch 621/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 1.3285 - val_loss: 113.6235\n",
            "Epoch 622/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.5853 - val_loss: 112.3248\n",
            "Epoch 623/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.4628 - val_loss: 114.8181\n",
            "Epoch 624/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.2669 - val_loss: 113.4427\n",
            "Epoch 625/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.1350 - val_loss: 113.6141\n",
            "Epoch 626/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1084 - val_loss: 113.5344\n",
            "Epoch 627/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.0784 - val_loss: 113.9526\n",
            "Epoch 628/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.0711 - val_loss: 113.0415\n",
            "Epoch 629/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.0706 - val_loss: 113.1695\n",
            "Epoch 630/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.0826 - val_loss: 113.3939\n",
            "Epoch 631/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1788 - val_loss: 114.0034\n",
            "Epoch 632/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.2390 - val_loss: 114.0661\n",
            "Epoch 633/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.7727 - val_loss: 114.3329\n",
            "Epoch 634/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.3922 - val_loss: 113.8502\n",
            "Epoch 635/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.5686 - val_loss: 112.7628\n",
            "Epoch 636/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.5109 - val_loss: 112.6587\n",
            "Epoch 637/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.4498 - val_loss: 113.4585\n",
            "Epoch 638/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.2668 - val_loss: 115.4683\n",
            "Epoch 639/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.7537 - val_loss: 111.7874\n",
            "Epoch 640/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 2.5120 - val_loss: 115.8646\n",
            "Epoch 641/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 6.4111 - val_loss: 111.0801\n",
            "Epoch 642/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 2.0553 - val_loss: 113.4509\n",
            "Epoch 643/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 1.5529 - val_loss: 112.9808\n",
            "Epoch 644/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.8443 - val_loss: 113.0620\n",
            "Epoch 645/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.6676 - val_loss: 111.5402\n",
            "Epoch 646/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.6457 - val_loss: 113.7512\n",
            "Epoch 647/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.3628 - val_loss: 114.1653\n",
            "Epoch 648/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.2948 - val_loss: 113.1057\n",
            "Epoch 649/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1892 - val_loss: 111.7145\n",
            "Epoch 650/1000\n",
            "1500/1500 [==============================] - 0s 145us/step - loss: 0.0865 - val_loss: 112.0784\n",
            "Epoch 651/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.2979 - val_loss: 111.4274\n",
            "Epoch 652/1000\n",
            "1500/1500 [==============================] - 0s 147us/step - loss: 1.4017 - val_loss: 113.2048\n",
            "Epoch 653/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.5883 - val_loss: 112.4744\n",
            "Epoch 654/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.3973 - val_loss: 111.8267\n",
            "Epoch 655/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.4855 - val_loss: 112.8256\n",
            "Epoch 656/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.6263 - val_loss: 112.8201\n",
            "Epoch 657/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.5829 - val_loss: 110.6199\n",
            "Epoch 658/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.4182 - val_loss: 112.3684\n",
            "Epoch 659/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.2453 - val_loss: 112.7176\n",
            "Epoch 660/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.2641 - val_loss: 114.4065\n",
            "Epoch 661/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.2429 - val_loss: 113.8378\n",
            "Epoch 662/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.4979 - val_loss: 115.5863\n",
            "Epoch 663/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.3929 - val_loss: 111.9135\n",
            "Epoch 664/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.2186 - val_loss: 113.2188\n",
            "Epoch 665/1000\n",
            "1500/1500 [==============================] - 0s 145us/step - loss: 0.2813 - val_loss: 111.6098\n",
            "Epoch 666/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.2251 - val_loss: 112.0335\n",
            "Epoch 667/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.3070 - val_loss: 113.7189\n",
            "Epoch 668/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.6256 - val_loss: 115.3095\n",
            "Epoch 669/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 2.1417 - val_loss: 115.6154\n",
            "Epoch 670/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 2.4643 - val_loss: 116.0331\n",
            "Epoch 671/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 2.9957 - val_loss: 111.2143\n",
            "Epoch 672/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 1.2594 - val_loss: 112.4804\n",
            "Epoch 673/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 1.0546 - val_loss: 111.0517\n",
            "Epoch 674/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 1.0258 - val_loss: 115.3258\n",
            "Epoch 675/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.3984 - val_loss: 112.4900\n",
            "Epoch 676/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 1.3178 - val_loss: 112.2255\n",
            "Epoch 677/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.6979 - val_loss: 111.7981\n",
            "Epoch 678/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.5352 - val_loss: 112.4599\n",
            "Epoch 679/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.3841 - val_loss: 114.6332\n",
            "Epoch 680/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.6887 - val_loss: 113.2259\n",
            "Epoch 681/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.4965 - val_loss: 112.2772\n",
            "Epoch 682/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.2471 - val_loss: 112.2677\n",
            "Epoch 683/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.1770 - val_loss: 111.9365\n",
            "Epoch 684/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.0958 - val_loss: 112.7131\n",
            "Epoch 685/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.2568 - val_loss: 113.3512\n",
            "Epoch 686/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.8687 - val_loss: 113.5713\n",
            "Epoch 687/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.6322 - val_loss: 111.1274\n",
            "Epoch 688/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.8544 - val_loss: 112.8765\n",
            "Epoch 689/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.7882 - val_loss: 113.3088\n",
            "Epoch 690/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 1.5245 - val_loss: 115.1416\n",
            "Epoch 691/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 1.6930 - val_loss: 115.6680\n",
            "Epoch 692/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 1.0478 - val_loss: 112.2545\n",
            "Epoch 693/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.7201 - val_loss: 113.6887\n",
            "Epoch 694/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.3625 - val_loss: 112.1426\n",
            "Epoch 695/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.1821 - val_loss: 111.5218\n",
            "Epoch 696/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.1587 - val_loss: 111.2482\n",
            "Epoch 697/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.2326 - val_loss: 111.8698\n",
            "Epoch 698/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.2159 - val_loss: 111.6146\n",
            "Epoch 699/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.1575 - val_loss: 110.9594\n",
            "Epoch 700/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1718 - val_loss: 112.8143\n",
            "Epoch 701/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1522 - val_loss: 112.9204\n",
            "Epoch 702/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.1468 - val_loss: 112.1499\n",
            "Epoch 703/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.1055 - val_loss: 111.7469\n",
            "Epoch 704/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.1026 - val_loss: 112.4590\n",
            "Epoch 705/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1431 - val_loss: 114.2508\n",
            "Epoch 706/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.7113 - val_loss: 116.7912\n",
            "Epoch 707/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 2.0139 - val_loss: 111.8560\n",
            "Epoch 708/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 8.4076 - val_loss: 112.3816\n",
            "Epoch 709/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 4.8312 - val_loss: 113.2188\n",
            "Epoch 710/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 2.9188 - val_loss: 120.1454\n",
            "Epoch 711/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 1.5347 - val_loss: 112.3146\n",
            "Epoch 712/1000\n",
            "1500/1500 [==============================] - 0s 149us/step - loss: 0.6676 - val_loss: 110.6306\n",
            "Epoch 713/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.5193 - val_loss: 110.7879\n",
            "Epoch 714/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.8960 - val_loss: 113.6752\n",
            "Epoch 715/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.7110 - val_loss: 112.4600\n",
            "Epoch 716/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.7922 - val_loss: 112.1189\n",
            "Epoch 717/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.3179 - val_loss: 111.5924\n",
            "Epoch 718/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.2013 - val_loss: 111.4445\n",
            "Epoch 719/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.2376 - val_loss: 110.6966\n",
            "Epoch 720/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.3431 - val_loss: 112.5330\n",
            "Epoch 721/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1384 - val_loss: 112.1107\n",
            "Epoch 722/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.1939 - val_loss: 111.3158\n",
            "Epoch 723/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.2151 - val_loss: 111.9084\n",
            "Epoch 724/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.1290 - val_loss: 111.0144\n",
            "Epoch 725/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.2395 - val_loss: 111.5601\n",
            "Epoch 726/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.2554 - val_loss: 111.8048\n",
            "Epoch 727/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.1907 - val_loss: 114.4780\n",
            "Epoch 728/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.2303 - val_loss: 110.9460\n",
            "Epoch 729/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.1328 - val_loss: 112.6988\n",
            "Epoch 730/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.1302 - val_loss: 111.1894\n",
            "Epoch 731/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.0959 - val_loss: 111.3243\n",
            "Epoch 732/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.2780 - val_loss: 111.3656\n",
            "Epoch 733/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.3992 - val_loss: 112.9347\n",
            "Epoch 734/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.6600 - val_loss: 113.4487\n",
            "Epoch 735/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.4386 - val_loss: 111.9554\n",
            "Epoch 736/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.2804 - val_loss: 112.1530\n",
            "Epoch 737/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.2828 - val_loss: 111.3183\n",
            "Epoch 738/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.7310 - val_loss: 112.1379\n",
            "Epoch 739/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.7916 - val_loss: 110.6536\n",
            "Epoch 740/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 2.6081 - val_loss: 112.9191\n",
            "Epoch 741/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 2.7634 - val_loss: 116.9190\n",
            "Epoch 742/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 2.1461 - val_loss: 116.8238\n",
            "Epoch 743/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 2.1642 - val_loss: 111.7222\n",
            "Epoch 744/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 1.0102 - val_loss: 110.4478\n",
            "Epoch 745/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.7712 - val_loss: 110.1247\n",
            "Epoch 746/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 1.2815 - val_loss: 110.9286\n",
            "Epoch 747/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.8555 - val_loss: 112.0857\n",
            "Epoch 748/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.6353 - val_loss: 111.0428\n",
            "Epoch 749/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.3314 - val_loss: 112.5520\n",
            "Epoch 750/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.2062 - val_loss: 113.1977\n",
            "Epoch 751/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.2796 - val_loss: 111.0962\n",
            "Epoch 752/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.2147 - val_loss: 112.5586\n",
            "Epoch 753/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.9179 - val_loss: 113.2571\n",
            "Epoch 754/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.8177 - val_loss: 111.1898\n",
            "Epoch 755/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.8514 - val_loss: 113.2068\n",
            "Epoch 756/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.3873 - val_loss: 111.3880\n",
            "Epoch 757/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.2680 - val_loss: 110.7104\n",
            "Epoch 758/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.2958 - val_loss: 111.0798\n",
            "Epoch 759/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.1805 - val_loss: 112.1408\n",
            "Epoch 760/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.1234 - val_loss: 111.3866\n",
            "Epoch 761/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.2923 - val_loss: 110.7508\n",
            "Epoch 762/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.8693 - val_loss: 111.3191\n",
            "Epoch 763/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 1.2853 - val_loss: 115.0037\n",
            "Epoch 764/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.8315 - val_loss: 115.1859\n",
            "Epoch 765/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 1.9318 - val_loss: 112.3641\n",
            "Epoch 766/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 1.3883 - val_loss: 112.0663\n",
            "Epoch 767/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 1.3070 - val_loss: 112.5062\n",
            "Epoch 768/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 2.6252 - val_loss: 112.1150\n",
            "Epoch 769/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 1.3647 - val_loss: 112.7704\n",
            "Epoch 770/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 1.1614 - val_loss: 111.2673\n",
            "Epoch 771/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.8482 - val_loss: 111.5095\n",
            "Epoch 772/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.9240 - val_loss: 110.0616\n",
            "Epoch 773/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.9163 - val_loss: 111.5473\n",
            "Epoch 774/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 1.9636 - val_loss: 116.3137\n",
            "Epoch 775/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 1.8333 - val_loss: 113.3233\n",
            "Epoch 776/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.7628 - val_loss: 111.8215\n",
            "Epoch 777/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.4588 - val_loss: 110.6429\n",
            "Epoch 778/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.2190 - val_loss: 109.9908\n",
            "Epoch 779/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.2139 - val_loss: 110.9276\n",
            "Epoch 780/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.1049 - val_loss: 110.2397\n",
            "Epoch 781/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.0939 - val_loss: 110.3665\n",
            "Epoch 782/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.0729 - val_loss: 111.3420\n",
            "Epoch 783/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.0555 - val_loss: 110.9739\n",
            "Epoch 784/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.0641 - val_loss: 110.6697\n",
            "Epoch 785/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.1549 - val_loss: 111.5289\n",
            "Epoch 786/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.0793 - val_loss: 111.6250\n",
            "Epoch 787/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.3480 - val_loss: 111.5858\n",
            "Epoch 788/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.3672 - val_loss: 111.8986\n",
            "Epoch 789/1000\n",
            "1500/1500 [==============================] - 0s 152us/step - loss: 0.2568 - val_loss: 111.7904\n",
            "Epoch 790/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.2464 - val_loss: 112.1496\n",
            "Epoch 791/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.4084 - val_loss: 109.8415\n",
            "Epoch 792/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 0.8051 - val_loss: 110.6327\n",
            "Epoch 793/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.5323 - val_loss: 109.7591\n",
            "Epoch 794/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.3609 - val_loss: 113.6520\n",
            "Epoch 795/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 1.2891 - val_loss: 108.7269\n",
            "Epoch 796/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.9018 - val_loss: 111.1031\n",
            "Epoch 797/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.3361 - val_loss: 113.4242\n",
            "Epoch 798/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 1.7610 - val_loss: 113.2197\n",
            "Epoch 799/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 2.5154 - val_loss: 112.5299\n",
            "Epoch 800/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 1.9479 - val_loss: 112.9730\n",
            "Epoch 801/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 1.5054 - val_loss: 113.8582\n",
            "Epoch 802/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.3537 - val_loss: 116.5820\n",
            "Epoch 803/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.4347 - val_loss: 113.2596\n",
            "Epoch 804/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 1.3367 - val_loss: 111.6689\n",
            "Epoch 805/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.4122 - val_loss: 111.4427\n",
            "Epoch 806/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.2931 - val_loss: 113.0590\n",
            "Epoch 807/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.3589 - val_loss: 109.9830\n",
            "Epoch 808/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.3971 - val_loss: 111.0625\n",
            "Epoch 809/1000\n",
            "1500/1500 [==============================] - 0s 147us/step - loss: 0.4082 - val_loss: 110.9393\n",
            "Epoch 810/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.5388 - val_loss: 109.7421\n",
            "Epoch 811/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 1.7164 - val_loss: 111.7524\n",
            "Epoch 812/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 1.1618 - val_loss: 113.4184\n",
            "Epoch 813/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 1.3038 - val_loss: 113.4424\n",
            "Epoch 814/1000\n",
            "1500/1500 [==============================] - 0s 151us/step - loss: 0.5134 - val_loss: 111.4730\n",
            "Epoch 815/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.3442 - val_loss: 112.2569\n",
            "Epoch 816/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.2933 - val_loss: 111.7522\n",
            "Epoch 817/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.1432 - val_loss: 111.5518\n",
            "Epoch 818/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.1339 - val_loss: 111.6235\n",
            "Epoch 819/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.1175 - val_loss: 110.9139\n",
            "Epoch 820/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.2034 - val_loss: 111.7541\n",
            "Epoch 821/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.2116 - val_loss: 111.8857\n",
            "Epoch 822/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.1876 - val_loss: 112.2455\n",
            "Epoch 823/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.1967 - val_loss: 111.7564\n",
            "Epoch 824/1000\n",
            "1500/1500 [==============================] - 0s 144us/step - loss: 0.3428 - val_loss: 113.0267\n",
            "Epoch 825/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.6085 - val_loss: 111.4634\n",
            "Epoch 826/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.0720 - val_loss: 115.2523\n",
            "Epoch 827/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 1.2759 - val_loss: 112.8501\n",
            "Epoch 828/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 2.1527 - val_loss: 115.6079\n",
            "Epoch 829/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 5.5621 - val_loss: 113.2000\n",
            "Epoch 830/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 4.0404 - val_loss: 110.0783\n",
            "Epoch 831/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 1.4890 - val_loss: 111.1806\n",
            "Epoch 832/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.6899 - val_loss: 111.9988\n",
            "Epoch 833/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.6417 - val_loss: 110.0472\n",
            "Epoch 834/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.2844 - val_loss: 111.6220\n",
            "Epoch 835/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.1750 - val_loss: 111.4850\n",
            "Epoch 836/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.0999 - val_loss: 111.3505\n",
            "Epoch 837/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.0686 - val_loss: 111.2906\n",
            "Epoch 838/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 0.0672 - val_loss: 112.1057\n",
            "Epoch 839/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.4218 - val_loss: 112.1228\n",
            "Epoch 840/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.2899 - val_loss: 110.2729\n",
            "Epoch 841/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.4138 - val_loss: 112.5506\n",
            "Epoch 842/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.2775 - val_loss: 111.5140\n",
            "Epoch 843/1000\n",
            "1500/1500 [==============================] - 0s 154us/step - loss: 0.1691 - val_loss: 112.0473\n",
            "Epoch 844/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.0958 - val_loss: 110.6477\n",
            "Epoch 845/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.0758 - val_loss: 111.8792\n",
            "Epoch 846/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1261 - val_loss: 111.3214\n",
            "Epoch 847/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.0819 - val_loss: 110.7943\n",
            "Epoch 848/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.0910 - val_loss: 111.3835\n",
            "Epoch 849/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1175 - val_loss: 111.6704\n",
            "Epoch 850/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1580 - val_loss: 110.3246\n",
            "Epoch 851/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1787 - val_loss: 110.7307\n",
            "Epoch 852/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 0.1146 - val_loss: 111.3585\n",
            "Epoch 853/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.2459 - val_loss: 110.4796\n",
            "Epoch 854/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 1.5552 - val_loss: 111.3358\n",
            "Epoch 855/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 1.0643 - val_loss: 114.7435\n",
            "Epoch 856/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 1.4883 - val_loss: 113.9052\n",
            "Epoch 857/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 2.4246 - val_loss: 116.0754\n",
            "Epoch 858/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 2.6080 - val_loss: 113.4875\n",
            "Epoch 859/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 1.7758 - val_loss: 111.1996\n",
            "Epoch 860/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 1.8923 - val_loss: 111.1077\n",
            "Epoch 861/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.6233 - val_loss: 109.5864\n",
            "Epoch 862/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.5175 - val_loss: 111.8106\n",
            "Epoch 863/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.4217 - val_loss: 110.1821\n",
            "Epoch 864/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.2489 - val_loss: 109.7745\n",
            "Epoch 865/1000\n",
            "1500/1500 [==============================] - 0s 144us/step - loss: 0.2382 - val_loss: 111.3831\n",
            "Epoch 866/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.1566 - val_loss: 110.1765\n",
            "Epoch 867/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.1897 - val_loss: 109.4459\n",
            "Epoch 868/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.2006 - val_loss: 110.3530\n",
            "Epoch 869/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.2368 - val_loss: 111.0856\n",
            "Epoch 870/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.3412 - val_loss: 110.2203\n",
            "Epoch 871/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.2967 - val_loss: 110.5464\n",
            "Epoch 872/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.1754 - val_loss: 111.7296\n",
            "Epoch 873/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.1925 - val_loss: 112.3543\n",
            "Epoch 874/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.4401 - val_loss: 110.5008\n",
            "Epoch 875/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.6272 - val_loss: 109.9462\n",
            "Epoch 876/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.4480 - val_loss: 110.2997\n",
            "Epoch 877/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.3488 - val_loss: 110.3475\n",
            "Epoch 878/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 1.0147 - val_loss: 110.6612\n",
            "Epoch 879/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 1.1447 - val_loss: 111.2344\n",
            "Epoch 880/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.5474 - val_loss: 110.6777\n",
            "Epoch 881/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.3312 - val_loss: 111.8991\n",
            "Epoch 882/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.3435 - val_loss: 110.6106\n",
            "Epoch 883/1000\n",
            "1500/1500 [==============================] - 0s 144us/step - loss: 0.2654 - val_loss: 112.2539\n",
            "Epoch 884/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.2936 - val_loss: 109.1057\n",
            "Epoch 885/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.5857 - val_loss: 110.8248\n",
            "Epoch 886/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.6520 - val_loss: 110.5242\n",
            "Epoch 887/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 1.3622 - val_loss: 109.4830\n",
            "Epoch 888/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 2.3850 - val_loss: 108.9299\n",
            "Epoch 889/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 3.2606 - val_loss: 109.6932\n",
            "Epoch 890/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.8067 - val_loss: 109.1648\n",
            "Epoch 891/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.8367 - val_loss: 110.7558\n",
            "Epoch 892/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.5326 - val_loss: 110.7400\n",
            "Epoch 893/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.2260 - val_loss: 110.0067\n",
            "Epoch 894/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.1466 - val_loss: 110.4036\n",
            "Epoch 895/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.1052 - val_loss: 111.8011\n",
            "Epoch 896/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.0952 - val_loss: 110.9311\n",
            "Epoch 897/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.0653 - val_loss: 110.3329\n",
            "Epoch 898/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 0.0550 - val_loss: 110.5850\n",
            "Epoch 899/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.0902 - val_loss: 110.7320\n",
            "Epoch 900/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.0602 - val_loss: 110.1723\n",
            "Epoch 901/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.0704 - val_loss: 110.5106\n",
            "Epoch 902/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.0891 - val_loss: 111.2213\n",
            "Epoch 903/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.1147 - val_loss: 109.7933\n",
            "Epoch 904/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.1348 - val_loss: 111.0805\n",
            "Epoch 905/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.2317 - val_loss: 109.5380\n",
            "Epoch 906/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.3435 - val_loss: 110.9872\n",
            "Epoch 907/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.3388 - val_loss: 111.4114\n",
            "Epoch 908/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.3422 - val_loss: 112.6612\n",
            "Epoch 909/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.5985 - val_loss: 110.1239\n",
            "Epoch 910/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.7447 - val_loss: 111.2252\n",
            "Epoch 911/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.9241 - val_loss: 112.1455\n",
            "Epoch 912/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 1.2175 - val_loss: 109.9545\n",
            "Epoch 913/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 1.2111 - val_loss: 109.9668\n",
            "Epoch 914/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.7430 - val_loss: 111.9535\n",
            "Epoch 915/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 1.7283 - val_loss: 118.4358\n",
            "Epoch 916/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 3.9400 - val_loss: 109.9364\n",
            "Epoch 917/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 4.9522 - val_loss: 113.1546\n",
            "Epoch 918/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 3.0117 - val_loss: 112.1141\n",
            "Epoch 919/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 2.8337 - val_loss: 110.4361\n",
            "Epoch 920/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.8312 - val_loss: 109.2561\n",
            "Epoch 921/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.3951 - val_loss: 110.3064\n",
            "Epoch 922/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.2756 - val_loss: 109.5056\n",
            "Epoch 923/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.2108 - val_loss: 110.4975\n",
            "Epoch 924/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.1204 - val_loss: 109.8877\n",
            "Epoch 925/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 0.1327 - val_loss: 109.6656\n",
            "Epoch 926/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.0959 - val_loss: 109.6674\n",
            "Epoch 927/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.0565 - val_loss: 109.3488\n",
            "Epoch 928/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.0363 - val_loss: 110.2375\n",
            "Epoch 929/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.0533 - val_loss: 109.9934\n",
            "Epoch 930/1000\n",
            "1500/1500 [==============================] - 0s 146us/step - loss: 0.0305 - val_loss: 109.8582\n",
            "Epoch 931/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.0138 - val_loss: 109.6975\n",
            "Epoch 932/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.0131 - val_loss: 109.8328\n",
            "Epoch 933/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.0176 - val_loss: 109.9777\n",
            "Epoch 934/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.0140 - val_loss: 109.7647\n",
            "Epoch 935/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.0114 - val_loss: 110.2222\n",
            "Epoch 936/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 0.0149 - val_loss: 109.9807\n",
            "Epoch 937/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.0335 - val_loss: 109.2993\n",
            "Epoch 938/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1035 - val_loss: 110.5587\n",
            "Epoch 939/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.0621 - val_loss: 109.6437\n",
            "Epoch 940/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.1175 - val_loss: 109.3346\n",
            "Epoch 941/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1761 - val_loss: 110.8735\n",
            "Epoch 942/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.5028 - val_loss: 109.3283\n",
            "Epoch 943/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 1.9296 - val_loss: 110.8206\n",
            "Epoch 944/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 1.7013 - val_loss: 111.3216\n",
            "Epoch 945/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 1.3244 - val_loss: 110.8888\n",
            "Epoch 946/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 1.4821 - val_loss: 110.3348\n",
            "Epoch 947/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.7442 - val_loss: 110.4949\n",
            "Epoch 948/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 1.8169 - val_loss: 109.3981\n",
            "Epoch 949/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 1.1668 - val_loss: 108.9686\n",
            "Epoch 950/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.8329 - val_loss: 110.2922\n",
            "Epoch 951/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.2995 - val_loss: 112.0178\n",
            "Epoch 952/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.2841 - val_loss: 109.8857\n",
            "Epoch 953/1000\n",
            "1500/1500 [==============================] - 0s 140us/step - loss: 0.3081 - val_loss: 110.5867\n",
            "Epoch 954/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.2955 - val_loss: 109.0643\n",
            "Epoch 955/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.4007 - val_loss: 110.3824\n",
            "Epoch 956/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.4974 - val_loss: 112.4492\n",
            "Epoch 957/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.4461 - val_loss: 109.3555\n",
            "Epoch 958/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.5297 - val_loss: 114.8864\n",
            "Epoch 959/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.7872 - val_loss: 110.0655\n",
            "Epoch 960/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 1.7490 - val_loss: 115.6215\n",
            "Epoch 961/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 1.5303 - val_loss: 112.3192\n",
            "Epoch 962/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.7813 - val_loss: 111.1073\n",
            "Epoch 963/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.8723 - val_loss: 110.5344\n",
            "Epoch 964/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 0.5334 - val_loss: 110.2246\n",
            "Epoch 965/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.2328 - val_loss: 109.5906\n",
            "Epoch 966/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.1967 - val_loss: 109.4487\n",
            "Epoch 967/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 0.1571 - val_loss: 111.9646\n",
            "Epoch 968/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 0.1889 - val_loss: 109.6674\n",
            "Epoch 969/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.1216 - val_loss: 110.1765\n",
            "Epoch 970/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.1753 - val_loss: 110.3311\n",
            "Epoch 971/1000\n",
            "1500/1500 [==============================] - 0s 137us/step - loss: 0.1140 - val_loss: 109.8822\n",
            "Epoch 972/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.2614 - val_loss: 108.9010\n",
            "Epoch 973/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.2781 - val_loss: 110.2380\n",
            "Epoch 974/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.1469 - val_loss: 110.0393\n",
            "Epoch 975/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.1386 - val_loss: 110.1621\n",
            "Epoch 976/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.1103 - val_loss: 109.9340\n",
            "Epoch 977/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.3166 - val_loss: 110.1098\n",
            "Epoch 978/1000\n",
            "1500/1500 [==============================] - 0s 146us/step - loss: 0.6192 - val_loss: 108.9046\n",
            "Epoch 979/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 5.4560 - val_loss: 114.0110\n",
            "Epoch 980/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 6.2001 - val_loss: 113.1882\n",
            "Epoch 981/1000\n",
            "1500/1500 [==============================] - 0s 139us/step - loss: 1.5506 - val_loss: 111.6966\n",
            "Epoch 982/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.6367 - val_loss: 110.9668\n",
            "Epoch 983/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.2971 - val_loss: 111.3790\n",
            "Epoch 984/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.2105 - val_loss: 110.1051\n",
            "Epoch 985/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.3052 - val_loss: 110.1509\n",
            "Epoch 986/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.1428 - val_loss: 110.6704\n",
            "Epoch 987/1000\n",
            "1500/1500 [==============================] - 0s 138us/step - loss: 0.1057 - val_loss: 110.0705\n",
            "Epoch 988/1000\n",
            "1500/1500 [==============================] - 0s 142us/step - loss: 0.0679 - val_loss: 110.6546\n",
            "Epoch 989/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.0446 - val_loss: 110.1451\n",
            "Epoch 990/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.0399 - val_loss: 110.4255\n",
            "Epoch 991/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 0.0271 - val_loss: 110.4820\n",
            "Epoch 992/1000\n",
            "1500/1500 [==============================] - 0s 132us/step - loss: 0.0244 - val_loss: 110.1968\n",
            "Epoch 993/1000\n",
            "1500/1500 [==============================] - 0s 141us/step - loss: 0.0295 - val_loss: 110.2112\n",
            "Epoch 994/1000\n",
            "1500/1500 [==============================] - 0s 130us/step - loss: 0.0299 - val_loss: 109.9378\n",
            "Epoch 995/1000\n",
            "1500/1500 [==============================] - 0s 131us/step - loss: 0.0389 - val_loss: 110.8433\n",
            "Epoch 996/1000\n",
            "1500/1500 [==============================] - 0s 135us/step - loss: 0.0281 - val_loss: 109.9616\n",
            "Epoch 997/1000\n",
            "1500/1500 [==============================] - 0s 136us/step - loss: 0.0320 - val_loss: 110.6851\n",
            "Epoch 998/1000\n",
            "1500/1500 [==============================] - 0s 143us/step - loss: 0.0558 - val_loss: 110.6165\n",
            "Epoch 999/1000\n",
            "1500/1500 [==============================] - 0s 133us/step - loss: 0.1631 - val_loss: 110.6964\n",
            "Epoch 1000/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.1367 - val_loss: 110.8254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRjbE905m0zm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "9fa015f0-665b-4e1a-9ae7-ad78e0d4410e"
      },
      "source": [
        "# 5. 학습과정 살펴보기\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.ylim(0.0, 300.0)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YADj3sROnPD9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "430c4e92-4480-4470-fdd5-1d82d8b6a6ac"
      },
      "source": [
        "# 6. 모델 평가하기\n",
        "score = model.evaluate(x_test_1d, y_test, batch_size=32)\n",
        "\n",
        "print(score)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 0s 115us/step\n",
            "90.07034088134766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQYwlK2KnXZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "6b70eb62-958e-400e-8c1c-0fb4b454a2b2"
      },
      "source": [
        "# 7. 모델 사용하기\n",
        "yhat_test = model.predict(x_test_1d, batch_size=32)\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt_row = 5\n",
        "plt_col = 5\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (10, 10)\n",
        "\n",
        "f, axarr = plt.subplots(plt_row, plt_col)\n",
        "\n",
        "for i in range(plt_row * plt_col):\n",
        "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
        "    sub_plt.axis('off')\n",
        "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
        "    sub_plt.set_title('R %d P %.1f' %(y_test[i][0], yhat_test[i][0]))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70NFkUGdn5Wn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}