{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Convolutional_neural_network_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiJOR--ssHzL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9e0959e-8cde-4007-8f7c-c8cb3078d96b"
      },
      "source": [
        "# 0. 사용할 패키지 불러오기\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "width = 16\n",
        "height = 16\n",
        "\n",
        "def generate_dataset(samples):\n",
        "    ds_x = []\n",
        "    ds_y = []\n",
        "    for it in range(samples):\n",
        "        num_pt = np.random.randint(0, width * height)\n",
        "        img = generate_image(num_pt)\n",
        "        ds_y.append(num_pt)\n",
        "        ds_x.append(img)\n",
        "    return np.array(ds_x), np.array(ds_y).reshape(samples, 1)\n",
        "\n",
        "def generate_image(points):\n",
        "    img = np.zeros((width, height))\n",
        "    pts = np.random.random((points, 2))\n",
        "    for ipt in pts:\n",
        "        img[int(ipt[0] * width), int(ipt[1] * height)] = 1\n",
        "    return img.reshape(width, height, 1)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnn1pHoit2wU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. 데이터셋 생성하기\n",
        "x_train, y_train = generate_dataset(1500)\n",
        "x_val, y_val = generate_dataset(300)\n",
        "x_test, y_test = generate_dataset(100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jByQEQAruAtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, 1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA79bfIxubdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3. 모델 학습과정 설정하기\n",
        "model.compile(loss='mse', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g-vKeMkuhYc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "801f45a5-a314-48b6-8c90-6ea7398f032b"
      },
      "source": [
        "# 4. 모델 학습시키기\n",
        "hist = model.fit(x_train, y_train, batch_size=32, epochs=1000, validation_data=(x_val, y_val))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1500 samples, validate on 300 samples\n",
            "Epoch 1/1000\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 12210.2331 - val_loss: 1965.4662\n",
            "Epoch 2/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 1492.0017 - val_loss: 1164.0957\n",
            "Epoch 3/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 1062.5636 - val_loss: 903.3186\n",
            "Epoch 4/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 847.1869 - val_loss: 712.7196\n",
            "Epoch 5/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 672.8015 - val_loss: 550.7358\n",
            "Epoch 6/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 485.8533 - val_loss: 326.7621\n",
            "Epoch 7/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 333.3797 - val_loss: 255.1111\n",
            "Epoch 8/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 259.0905 - val_loss: 238.3539\n",
            "Epoch 9/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 245.9227 - val_loss: 214.3610\n",
            "Epoch 10/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 227.7177 - val_loss: 199.7042\n",
            "Epoch 11/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 224.6230 - val_loss: 182.4866\n",
            "Epoch 12/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 214.3077 - val_loss: 210.4306\n",
            "Epoch 13/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 202.7260 - val_loss: 174.0461\n",
            "Epoch 14/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 189.4392 - val_loss: 162.1115\n",
            "Epoch 15/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 187.1801 - val_loss: 155.6188\n",
            "Epoch 16/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 178.4084 - val_loss: 220.0521\n",
            "Epoch 17/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 178.6336 - val_loss: 169.4735\n",
            "Epoch 18/1000\n",
            "1500/1500 [==============================] - 0s 117us/step - loss: 174.0235 - val_loss: 152.6941\n",
            "Epoch 19/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 163.2499 - val_loss: 143.4618\n",
            "Epoch 20/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 174.8444 - val_loss: 139.3953\n",
            "Epoch 21/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 168.5002 - val_loss: 156.7838\n",
            "Epoch 22/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 177.0497 - val_loss: 138.5526\n",
            "Epoch 23/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 150.4083 - val_loss: 146.6186\n",
            "Epoch 24/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 154.9666 - val_loss: 138.9109\n",
            "Epoch 25/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 151.9465 - val_loss: 162.1405\n",
            "Epoch 26/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 151.5455 - val_loss: 143.6484\n",
            "Epoch 27/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 165.0998 - val_loss: 155.1961\n",
            "Epoch 28/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 144.6795 - val_loss: 147.2609\n",
            "Epoch 29/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 153.4670 - val_loss: 137.6768\n",
            "Epoch 30/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 141.5117 - val_loss: 131.1758\n",
            "Epoch 31/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 135.8049 - val_loss: 134.1535\n",
            "Epoch 32/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 133.7378 - val_loss: 132.7622\n",
            "Epoch 33/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 136.3626 - val_loss: 128.0521\n",
            "Epoch 34/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 134.5349 - val_loss: 135.3416\n",
            "Epoch 35/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 130.9928 - val_loss: 126.6119\n",
            "Epoch 36/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 126.9176 - val_loss: 129.4054\n",
            "Epoch 37/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 134.6415 - val_loss: 143.3704\n",
            "Epoch 38/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 140.1771 - val_loss: 144.7125\n",
            "Epoch 39/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 121.9531 - val_loss: 135.6812\n",
            "Epoch 40/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 118.9807 - val_loss: 132.7621\n",
            "Epoch 41/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 127.8840 - val_loss: 124.3125\n",
            "Epoch 42/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 120.2895 - val_loss: 121.9714\n",
            "Epoch 43/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 115.6348 - val_loss: 141.2426\n",
            "Epoch 44/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 116.3797 - val_loss: 125.7198\n",
            "Epoch 45/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 112.3797 - val_loss: 119.9779\n",
            "Epoch 46/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 109.4478 - val_loss: 137.4695\n",
            "Epoch 47/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 123.2327 - val_loss: 131.4371\n",
            "Epoch 48/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 110.8917 - val_loss: 128.7946\n",
            "Epoch 49/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 106.5496 - val_loss: 128.6864\n",
            "Epoch 50/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 104.4596 - val_loss: 120.0253\n",
            "Epoch 51/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 102.8415 - val_loss: 118.8784\n",
            "Epoch 52/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 115.0078 - val_loss: 134.2458\n",
            "Epoch 53/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 115.8869 - val_loss: 119.6758\n",
            "Epoch 54/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 104.3890 - val_loss: 126.6029\n",
            "Epoch 55/1000\n",
            "1500/1500 [==============================] - 0s 116us/step - loss: 101.1674 - val_loss: 166.6470\n",
            "Epoch 56/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 118.0019 - val_loss: 117.7684\n",
            "Epoch 57/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 98.3656 - val_loss: 138.8209\n",
            "Epoch 58/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 102.8303 - val_loss: 135.4538\n",
            "Epoch 59/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 95.2757 - val_loss: 139.0590\n",
            "Epoch 60/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 93.2725 - val_loss: 148.2250\n",
            "Epoch 61/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 92.1043 - val_loss: 127.5838\n",
            "Epoch 62/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 93.1763 - val_loss: 133.5560\n",
            "Epoch 63/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 98.8128 - val_loss: 116.9040\n",
            "Epoch 64/1000\n",
            "1500/1500 [==============================] - 0s 102us/step - loss: 86.7656 - val_loss: 132.9458\n",
            "Epoch 65/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 86.2032 - val_loss: 117.7225\n",
            "Epoch 66/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 84.6078 - val_loss: 137.2123\n",
            "Epoch 67/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 93.0872 - val_loss: 140.2989\n",
            "Epoch 68/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 84.6170 - val_loss: 117.7065\n",
            "Epoch 69/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 102.6551 - val_loss: 117.7117\n",
            "Epoch 70/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 89.0588 - val_loss: 120.1593\n",
            "Epoch 71/1000\n",
            "1500/1500 [==============================] - 0s 102us/step - loss: 90.8561 - val_loss: 121.6209\n",
            "Epoch 72/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 77.0365 - val_loss: 118.5742\n",
            "Epoch 73/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 93.9656 - val_loss: 154.0164\n",
            "Epoch 74/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 85.2711 - val_loss: 122.7807\n",
            "Epoch 75/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 77.0005 - val_loss: 143.2562\n",
            "Epoch 76/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 77.0607 - val_loss: 117.1236\n",
            "Epoch 77/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 73.0363 - val_loss: 121.6315\n",
            "Epoch 78/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 71.3116 - val_loss: 122.4424\n",
            "Epoch 79/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 72.7180 - val_loss: 145.7877\n",
            "Epoch 80/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 78.8828 - val_loss: 124.5644\n",
            "Epoch 81/1000\n",
            "1500/1500 [==============================] - 0s 124us/step - loss: 74.9510 - val_loss: 119.9950\n",
            "Epoch 82/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 68.4602 - val_loss: 121.5985\n",
            "Epoch 83/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 68.3033 - val_loss: 131.0064\n",
            "Epoch 84/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 71.9613 - val_loss: 131.9982\n",
            "Epoch 85/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 74.5463 - val_loss: 124.4452\n",
            "Epoch 86/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 81.2498 - val_loss: 135.2717\n",
            "Epoch 87/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 77.7342 - val_loss: 119.2736\n",
            "Epoch 88/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 73.8460 - val_loss: 161.2335\n",
            "Epoch 89/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 65.7269 - val_loss: 120.4099\n",
            "Epoch 90/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 63.1964 - val_loss: 123.3177\n",
            "Epoch 91/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 61.2751 - val_loss: 126.4369\n",
            "Epoch 92/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 62.7643 - val_loss: 124.4944\n",
            "Epoch 93/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 61.2737 - val_loss: 143.0334\n",
            "Epoch 94/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 73.3410 - val_loss: 124.3074\n",
            "Epoch 95/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 57.3665 - val_loss: 123.2942\n",
            "Epoch 96/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 53.9093 - val_loss: 123.7282\n",
            "Epoch 97/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 55.7480 - val_loss: 125.5929\n",
            "Epoch 98/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 53.3906 - val_loss: 134.3630\n",
            "Epoch 99/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 59.1964 - val_loss: 129.0210\n",
            "Epoch 100/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 55.2305 - val_loss: 124.7052\n",
            "Epoch 101/1000\n",
            "1500/1500 [==============================] - 0s 120us/step - loss: 54.4124 - val_loss: 123.5871\n",
            "Epoch 102/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 53.4095 - val_loss: 146.5376\n",
            "Epoch 103/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 57.1396 - val_loss: 180.4351\n",
            "Epoch 104/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 61.2273 - val_loss: 127.2886\n",
            "Epoch 105/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 51.0778 - val_loss: 130.1411\n",
            "Epoch 106/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 47.7876 - val_loss: 128.2444\n",
            "Epoch 107/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 50.8770 - val_loss: 125.2630\n",
            "Epoch 108/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 47.2667 - val_loss: 125.6301\n",
            "Epoch 109/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 44.0856 - val_loss: 126.7941\n",
            "Epoch 110/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 46.6110 - val_loss: 127.5578\n",
            "Epoch 111/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 48.4473 - val_loss: 126.0190\n",
            "Epoch 112/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 47.4937 - val_loss: 133.4636\n",
            "Epoch 113/1000\n",
            "1500/1500 [==============================] - 0s 119us/step - loss: 58.3536 - val_loss: 177.7659\n",
            "Epoch 114/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 55.9772 - val_loss: 163.3830\n",
            "Epoch 115/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 47.1928 - val_loss: 134.8516\n",
            "Epoch 116/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 44.7565 - val_loss: 134.2731\n",
            "Epoch 117/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 41.6946 - val_loss: 126.3147\n",
            "Epoch 118/1000\n",
            "1500/1500 [==============================] - 0s 119us/step - loss: 47.5519 - val_loss: 128.2297\n",
            "Epoch 119/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 38.4752 - val_loss: 146.6102\n",
            "Epoch 120/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 43.5785 - val_loss: 129.7597\n",
            "Epoch 121/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 37.8292 - val_loss: 131.6140\n",
            "Epoch 122/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 41.5678 - val_loss: 141.6403\n",
            "Epoch 123/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 38.3489 - val_loss: 163.7548\n",
            "Epoch 124/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 35.9969 - val_loss: 132.4609\n",
            "Epoch 125/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 34.3051 - val_loss: 140.9146\n",
            "Epoch 126/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 38.0161 - val_loss: 134.2214\n",
            "Epoch 127/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 37.5525 - val_loss: 138.9482\n",
            "Epoch 128/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 34.6590 - val_loss: 137.7775\n",
            "Epoch 129/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 35.0713 - val_loss: 146.9534\n",
            "Epoch 130/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 34.6481 - val_loss: 138.4518\n",
            "Epoch 131/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 31.1757 - val_loss: 138.7780\n",
            "Epoch 132/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 32.1854 - val_loss: 136.0352\n",
            "Epoch 133/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 28.6781 - val_loss: 135.9777\n",
            "Epoch 134/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 30.7060 - val_loss: 133.1258\n",
            "Epoch 135/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 30.7830 - val_loss: 151.9947\n",
            "Epoch 136/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 29.3072 - val_loss: 138.5743\n",
            "Epoch 137/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 27.2166 - val_loss: 134.1238\n",
            "Epoch 138/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 27.2729 - val_loss: 141.1980\n",
            "Epoch 139/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 30.2003 - val_loss: 149.1995\n",
            "Epoch 140/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 28.1493 - val_loss: 147.8458\n",
            "Epoch 141/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 27.9078 - val_loss: 140.7185\n",
            "Epoch 142/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 27.1248 - val_loss: 142.9962\n",
            "Epoch 143/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 25.2058 - val_loss: 140.6194\n",
            "Epoch 144/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 29.9439 - val_loss: 144.4098\n",
            "Epoch 145/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 26.6832 - val_loss: 135.7508\n",
            "Epoch 146/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 25.4954 - val_loss: 138.1927\n",
            "Epoch 147/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 39.9493 - val_loss: 145.7743\n",
            "Epoch 148/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 25.0030 - val_loss: 135.7148\n",
            "Epoch 149/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 21.1563 - val_loss: 138.4697\n",
            "Epoch 150/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 20.8471 - val_loss: 140.7537\n",
            "Epoch 151/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 21.9205 - val_loss: 144.0831\n",
            "Epoch 152/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 21.0830 - val_loss: 140.4045\n",
            "Epoch 153/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 23.0154 - val_loss: 147.6880\n",
            "Epoch 154/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 20.5575 - val_loss: 141.9861\n",
            "Epoch 155/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 19.0054 - val_loss: 139.2684\n",
            "Epoch 156/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 18.0301 - val_loss: 140.4290\n",
            "Epoch 157/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 19.0836 - val_loss: 139.2829\n",
            "Epoch 158/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 19.4193 - val_loss: 142.5448\n",
            "Epoch 159/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 19.8069 - val_loss: 145.3905\n",
            "Epoch 160/1000\n",
            "1500/1500 [==============================] - 0s 116us/step - loss: 18.3730 - val_loss: 144.9858\n",
            "Epoch 161/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 17.0688 - val_loss: 138.8052\n",
            "Epoch 162/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 16.8063 - val_loss: 141.8438\n",
            "Epoch 163/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 17.6493 - val_loss: 140.8727\n",
            "Epoch 164/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 16.1968 - val_loss: 141.9262\n",
            "Epoch 165/1000\n",
            "1500/1500 [==============================] - 0s 124us/step - loss: 15.2649 - val_loss: 140.6714\n",
            "Epoch 166/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 14.4207 - val_loss: 142.3782\n",
            "Epoch 167/1000\n",
            "1500/1500 [==============================] - 0s 119us/step - loss: 15.3879 - val_loss: 143.0190\n",
            "Epoch 168/1000\n",
            "1500/1500 [==============================] - 0s 119us/step - loss: 17.0906 - val_loss: 147.6739\n",
            "Epoch 169/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 15.1257 - val_loss: 150.3811\n",
            "Epoch 170/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 13.6602 - val_loss: 145.1866\n",
            "Epoch 171/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 13.0154 - val_loss: 145.4364\n",
            "Epoch 172/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 12.8628 - val_loss: 147.7333\n",
            "Epoch 173/1000\n",
            "1500/1500 [==============================] - 0s 117us/step - loss: 15.5289 - val_loss: 144.3793\n",
            "Epoch 174/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 13.1676 - val_loss: 144.7556\n",
            "Epoch 175/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 12.1877 - val_loss: 145.2768\n",
            "Epoch 176/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 12.6662 - val_loss: 155.7033\n",
            "Epoch 177/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 12.9752 - val_loss: 150.2441\n",
            "Epoch 178/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 11.6440 - val_loss: 151.6668\n",
            "Epoch 179/1000\n",
            "1500/1500 [==============================] - 0s 120us/step - loss: 12.5277 - val_loss: 145.3465\n",
            "Epoch 180/1000\n",
            "1500/1500 [==============================] - 0s 120us/step - loss: 10.1665 - val_loss: 148.6985\n",
            "Epoch 181/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 11.6971 - val_loss: 146.8591\n",
            "Epoch 182/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 10.4881 - val_loss: 148.1867\n",
            "Epoch 183/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 11.7558 - val_loss: 153.9995\n",
            "Epoch 184/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 9.5922 - val_loss: 153.0714\n",
            "Epoch 185/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 13.2086 - val_loss: 145.0918\n",
            "Epoch 186/1000\n",
            "1500/1500 [==============================] - 0s 117us/step - loss: 9.0612 - val_loss: 147.7442\n",
            "Epoch 187/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 9.2511 - val_loss: 148.0026\n",
            "Epoch 188/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 12.4362 - val_loss: 146.9590\n",
            "Epoch 189/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 11.6318 - val_loss: 144.6391\n",
            "Epoch 190/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 8.3704 - val_loss: 146.5109\n",
            "Epoch 191/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 7.6109 - val_loss: 147.7539\n",
            "Epoch 192/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 7.6749 - val_loss: 148.8633\n",
            "Epoch 193/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 7.4011 - val_loss: 148.5882\n",
            "Epoch 194/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 6.8460 - val_loss: 150.6774\n",
            "Epoch 195/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 9.6203 - val_loss: 165.4871\n",
            "Epoch 196/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 12.9812 - val_loss: 147.9313\n",
            "Epoch 197/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 7.0410 - val_loss: 152.1511\n",
            "Epoch 198/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 7.4832 - val_loss: 151.7743\n",
            "Epoch 199/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 7.3336 - val_loss: 150.8666\n",
            "Epoch 200/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 7.0139 - val_loss: 150.9697\n",
            "Epoch 201/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 5.9626 - val_loss: 151.7196\n",
            "Epoch 202/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 6.0181 - val_loss: 153.2320\n",
            "Epoch 203/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 6.0231 - val_loss: 152.4371\n",
            "Epoch 204/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 6.9865 - val_loss: 153.6664\n",
            "Epoch 205/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 6.1876 - val_loss: 150.7739\n",
            "Epoch 206/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 5.4468 - val_loss: 153.9669\n",
            "Epoch 207/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 5.3149 - val_loss: 154.4824\n",
            "Epoch 208/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 5.3912 - val_loss: 154.9823\n",
            "Epoch 209/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 4.8170 - val_loss: 156.3800\n",
            "Epoch 210/1000\n",
            "1500/1500 [==============================] - 0s 116us/step - loss: 4.6522 - val_loss: 154.9351\n",
            "Epoch 211/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 4.3430 - val_loss: 154.7799\n",
            "Epoch 212/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 4.0720 - val_loss: 159.6373\n",
            "Epoch 213/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 5.8930 - val_loss: 155.1350\n",
            "Epoch 214/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 3.8609 - val_loss: 159.7466\n",
            "Epoch 215/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 4.4656 - val_loss: 156.4336\n",
            "Epoch 216/1000\n",
            "1500/1500 [==============================] - 0s 123us/step - loss: 3.5765 - val_loss: 156.4482\n",
            "Epoch 217/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 4.0831 - val_loss: 160.4705\n",
            "Epoch 218/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 4.1097 - val_loss: 159.0522\n",
            "Epoch 219/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 4.4349 - val_loss: 156.0089\n",
            "Epoch 220/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 3.7363 - val_loss: 155.7327\n",
            "Epoch 221/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 3.6666 - val_loss: 156.2559\n",
            "Epoch 222/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 4.2211 - val_loss: 157.8307\n",
            "Epoch 223/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 3.6803 - val_loss: 158.4198\n",
            "Epoch 224/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 2.7696 - val_loss: 157.5268\n",
            "Epoch 225/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 3.8684 - val_loss: 157.9415\n",
            "Epoch 226/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 2.6291 - val_loss: 159.1297\n",
            "Epoch 227/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 2.9481 - val_loss: 159.0502\n",
            "Epoch 228/1000\n",
            "1500/1500 [==============================] - 0s 120us/step - loss: 2.6788 - val_loss: 160.4057\n",
            "Epoch 229/1000\n",
            "1500/1500 [==============================] - 0s 118us/step - loss: 3.6997 - val_loss: 159.5111\n",
            "Epoch 230/1000\n",
            "1500/1500 [==============================] - 0s 122us/step - loss: 2.6168 - val_loss: 158.7414\n",
            "Epoch 231/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 2.8577 - val_loss: 158.3045\n",
            "Epoch 232/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 3.2372 - val_loss: 160.1769\n",
            "Epoch 233/1000\n",
            "1500/1500 [==============================] - 0s 118us/step - loss: 3.1529 - val_loss: 158.0655\n",
            "Epoch 234/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 2.1964 - val_loss: 160.2413\n",
            "Epoch 235/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 1.8664 - val_loss: 158.2953\n",
            "Epoch 236/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 2.8367 - val_loss: 159.1451\n",
            "Epoch 237/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 9.1557 - val_loss: 160.0176\n",
            "Epoch 238/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 5.0992 - val_loss: 160.6017\n",
            "Epoch 239/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 3.4182 - val_loss: 160.4266\n",
            "Epoch 240/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 3.5491 - val_loss: 159.1990\n",
            "Epoch 241/1000\n",
            "1500/1500 [==============================] - 0s 120us/step - loss: 1.8487 - val_loss: 162.6726\n",
            "Epoch 242/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 2.4508 - val_loss: 160.1798\n",
            "Epoch 243/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.7931 - val_loss: 161.5319\n",
            "Epoch 244/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.4524 - val_loss: 159.9185\n",
            "Epoch 245/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 3.3669 - val_loss: 160.1665\n",
            "Epoch 246/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 2.4578 - val_loss: 160.4189\n",
            "Epoch 247/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 1.4218 - val_loss: 161.3409\n",
            "Epoch 248/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 1.1343 - val_loss: 163.2506\n",
            "Epoch 249/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 1.6878 - val_loss: 165.7435\n",
            "Epoch 250/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 1.6510 - val_loss: 162.0377\n",
            "Epoch 251/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 1.9954 - val_loss: 162.9854\n",
            "Epoch 252/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 4.4507 - val_loss: 162.0910\n",
            "Epoch 253/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 1.9135 - val_loss: 162.9970\n",
            "Epoch 254/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.4063 - val_loss: 164.5962\n",
            "Epoch 255/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 1.4024 - val_loss: 161.5345\n",
            "Epoch 256/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 1.1530 - val_loss: 166.4594\n",
            "Epoch 257/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.9830 - val_loss: 163.9119\n",
            "Epoch 258/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.8852 - val_loss: 163.6087\n",
            "Epoch 259/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.8144 - val_loss: 165.1416\n",
            "Epoch 260/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 0.9484 - val_loss: 164.3570\n",
            "Epoch 261/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 1.5108 - val_loss: 164.9790\n",
            "Epoch 262/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 1.2789 - val_loss: 164.6027\n",
            "Epoch 263/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.8674 - val_loss: 165.8789\n",
            "Epoch 264/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.7325 - val_loss: 164.8276\n",
            "Epoch 265/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.8719 - val_loss: 165.3906\n",
            "Epoch 266/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 0.8746 - val_loss: 164.1762\n",
            "Epoch 267/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.3731 - val_loss: 166.0301\n",
            "Epoch 268/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.9431 - val_loss: 165.8678\n",
            "Epoch 269/1000\n",
            "1500/1500 [==============================] - 0s 116us/step - loss: 0.7762 - val_loss: 164.8211\n",
            "Epoch 270/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.8308 - val_loss: 165.4760\n",
            "Epoch 271/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.6893 - val_loss: 164.1804\n",
            "Epoch 272/1000\n",
            "1500/1500 [==============================] - 0s 123us/step - loss: 0.9661 - val_loss: 164.8987\n",
            "Epoch 273/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.9502 - val_loss: 165.2400\n",
            "Epoch 274/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.5930 - val_loss: 165.3587\n",
            "Epoch 275/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.6923 - val_loss: 165.5835\n",
            "Epoch 276/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 1.2930 - val_loss: 166.8260\n",
            "Epoch 277/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.5014 - val_loss: 165.4019\n",
            "Epoch 278/1000\n",
            "1500/1500 [==============================] - 0s 123us/step - loss: 2.4726 - val_loss: 167.1814\n",
            "Epoch 279/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 1.4163 - val_loss: 166.6913\n",
            "Epoch 280/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 5.4182 - val_loss: 166.7065\n",
            "Epoch 281/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 13.2175 - val_loss: 162.8169\n",
            "Epoch 282/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 6.5349 - val_loss: 160.6099\n",
            "Epoch 283/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 4.5415 - val_loss: 161.2242\n",
            "Epoch 284/1000\n",
            "1500/1500 [==============================] - 0s 116us/step - loss: 2.1005 - val_loss: 165.1867\n",
            "Epoch 285/1000\n",
            "1500/1500 [==============================] - 0s 117us/step - loss: 1.1156 - val_loss: 165.2782\n",
            "Epoch 286/1000\n",
            "1500/1500 [==============================] - 0s 121us/step - loss: 0.5969 - val_loss: 165.8711\n",
            "Epoch 287/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.6526 - val_loss: 167.4118\n",
            "Epoch 288/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.8114 - val_loss: 168.3396\n",
            "Epoch 289/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 1.1417 - val_loss: 167.1292\n",
            "Epoch 290/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.8464 - val_loss: 168.9869\n",
            "Epoch 291/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.5401 - val_loss: 167.9575\n",
            "Epoch 292/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.3016 - val_loss: 167.1786\n",
            "Epoch 293/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.3805 - val_loss: 166.7549\n",
            "Epoch 294/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.2675 - val_loss: 167.1842\n",
            "Epoch 295/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.2544 - val_loss: 167.2684\n",
            "Epoch 296/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 0.2617 - val_loss: 167.0897\n",
            "Epoch 297/1000\n",
            "1500/1500 [==============================] - 0s 124us/step - loss: 0.2618 - val_loss: 168.4086\n",
            "Epoch 298/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.5962 - val_loss: 167.2558\n",
            "Epoch 299/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.4829 - val_loss: 168.6797\n",
            "Epoch 300/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 1.8174 - val_loss: 170.4564\n",
            "Epoch 301/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 1.6647 - val_loss: 166.9753\n",
            "Epoch 302/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.8569 - val_loss: 167.9425\n",
            "Epoch 303/1000\n",
            "1500/1500 [==============================] - 0s 119us/step - loss: 0.6547 - val_loss: 166.6537\n",
            "Epoch 304/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 1.6318 - val_loss: 167.6938\n",
            "Epoch 305/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 1.1892 - val_loss: 170.7697\n",
            "Epoch 306/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.5788 - val_loss: 169.5966\n",
            "Epoch 307/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.9613 - val_loss: 167.1561\n",
            "Epoch 308/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.7681 - val_loss: 168.1246\n",
            "Epoch 309/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.6153 - val_loss: 167.0915\n",
            "Epoch 310/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.4428 - val_loss: 167.8274\n",
            "Epoch 311/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.4862 - val_loss: 167.1920\n",
            "Epoch 312/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.4823 - val_loss: 168.2207\n",
            "Epoch 313/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.5535 - val_loss: 169.5387\n",
            "Epoch 314/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.7832 - val_loss: 166.8000\n",
            "Epoch 315/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 1.5957 - val_loss: 170.4240\n",
            "Epoch 316/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 1.3088 - val_loss: 168.0252\n",
            "Epoch 317/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 1.0226 - val_loss: 169.6939\n",
            "Epoch 318/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 1.7915 - val_loss: 168.3879\n",
            "Epoch 319/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 4.5929 - val_loss: 166.8297\n",
            "Epoch 320/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 3.8674 - val_loss: 165.9270\n",
            "Epoch 321/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 2.3803 - val_loss: 172.1229\n",
            "Epoch 322/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 4.1621 - val_loss: 167.0164\n",
            "Epoch 323/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 2.0151 - val_loss: 167.1846\n",
            "Epoch 324/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.7003 - val_loss: 167.1573\n",
            "Epoch 325/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.7836 - val_loss: 167.1913\n",
            "Epoch 326/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.6260 - val_loss: 169.0281\n",
            "Epoch 327/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.4562 - val_loss: 167.8665\n",
            "Epoch 328/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 0.6269 - val_loss: 167.1100\n",
            "Epoch 329/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.5157 - val_loss: 167.0577\n",
            "Epoch 330/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.4833 - val_loss: 167.3861\n",
            "Epoch 331/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.4056 - val_loss: 167.5206\n",
            "Epoch 332/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.2428 - val_loss: 167.7513\n",
            "Epoch 333/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.1348 - val_loss: 168.3869\n",
            "Epoch 334/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.1717 - val_loss: 167.6958\n",
            "Epoch 335/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.1130 - val_loss: 167.7759\n",
            "Epoch 336/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.0940 - val_loss: 168.3248\n",
            "Epoch 337/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.2043 - val_loss: 168.3153\n",
            "Epoch 338/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.1063 - val_loss: 167.9784\n",
            "Epoch 339/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 3.4870 - val_loss: 174.6322\n",
            "Epoch 340/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 5.3581 - val_loss: 170.4932\n",
            "Epoch 341/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 1.9708 - val_loss: 166.9469\n",
            "Epoch 342/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.8319 - val_loss: 167.0573\n",
            "Epoch 343/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.5310 - val_loss: 169.1778\n",
            "Epoch 344/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 1.1691 - val_loss: 170.7690\n",
            "Epoch 345/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 1.0082 - val_loss: 168.8432\n",
            "Epoch 346/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.7909 - val_loss: 167.5159\n",
            "Epoch 347/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.4658 - val_loss: 167.8325\n",
            "Epoch 348/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.6167 - val_loss: 168.8340\n",
            "Epoch 349/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.7772 - val_loss: 170.0215\n",
            "Epoch 350/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.3855 - val_loss: 168.5359\n",
            "Epoch 351/1000\n",
            "1500/1500 [==============================] - 0s 102us/step - loss: 0.4015 - val_loss: 168.0548\n",
            "Epoch 352/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.5056 - val_loss: 168.9582\n",
            "Epoch 353/1000\n",
            "1500/1500 [==============================] - 0s 124us/step - loss: 0.2765 - val_loss: 168.5689\n",
            "Epoch 354/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.5841 - val_loss: 169.2810\n",
            "Epoch 355/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.4947 - val_loss: 169.3482\n",
            "Epoch 356/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 2.7468 - val_loss: 166.1390\n",
            "Epoch 357/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 3.6707 - val_loss: 168.2204\n",
            "Epoch 358/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 3.3102 - val_loss: 168.4412\n",
            "Epoch 359/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 1.2512 - val_loss: 168.5007\n",
            "Epoch 360/1000\n",
            "1500/1500 [==============================] - 0s 117us/step - loss: 1.0074 - val_loss: 169.9853\n",
            "Epoch 361/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.3810 - val_loss: 168.3278\n",
            "Epoch 362/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.5477 - val_loss: 169.6417\n",
            "Epoch 363/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 1.2361 - val_loss: 168.5622\n",
            "Epoch 364/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.6447 - val_loss: 168.5858\n",
            "Epoch 365/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 4.2490 - val_loss: 182.8005\n",
            "Epoch 366/1000\n",
            "1500/1500 [==============================] - 0s 129us/step - loss: 17.8269 - val_loss: 166.4656\n",
            "Epoch 367/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 11.2946 - val_loss: 169.1455\n",
            "Epoch 368/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 2.9939 - val_loss: 167.1363\n",
            "Epoch 369/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 1.2973 - val_loss: 166.7601\n",
            "Epoch 370/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.8572 - val_loss: 166.8843\n",
            "Epoch 371/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.4112 - val_loss: 166.1863\n",
            "Epoch 372/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.3167 - val_loss: 167.0772\n",
            "Epoch 373/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.2573 - val_loss: 166.4090\n",
            "Epoch 374/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.2060 - val_loss: 167.0125\n",
            "Epoch 375/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.1912 - val_loss: 167.8487\n",
            "Epoch 376/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.2716 - val_loss: 166.8937\n",
            "Epoch 377/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.2822 - val_loss: 166.6758\n",
            "Epoch 378/1000\n",
            "1500/1500 [==============================] - 0s 121us/step - loss: 0.1267 - val_loss: 166.9110\n",
            "Epoch 379/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.1108 - val_loss: 167.7679\n",
            "Epoch 380/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.1059 - val_loss: 167.3487\n",
            "Epoch 381/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.0806 - val_loss: 167.1984\n",
            "Epoch 382/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.0534 - val_loss: 167.2802\n",
            "Epoch 383/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.0453 - val_loss: 167.3327\n",
            "Epoch 384/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.0558 - val_loss: 167.3665\n",
            "Epoch 385/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.1144 - val_loss: 167.4849\n",
            "Epoch 386/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.0767 - val_loss: 167.2432\n",
            "Epoch 387/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.0455 - val_loss: 167.3299\n",
            "Epoch 388/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.0423 - val_loss: 167.3357\n",
            "Epoch 389/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.0457 - val_loss: 167.3657\n",
            "Epoch 390/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.0766 - val_loss: 167.6625\n",
            "Epoch 391/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.1043 - val_loss: 168.3188\n",
            "Epoch 392/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.0986 - val_loss: 167.7370\n",
            "Epoch 393/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.5234 - val_loss: 168.4268\n",
            "Epoch 394/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.6513 - val_loss: 166.2629\n",
            "Epoch 395/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.3288 - val_loss: 167.6668\n",
            "Epoch 396/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.1693 - val_loss: 167.4280\n",
            "Epoch 397/1000\n",
            "1500/1500 [==============================] - 0s 118us/step - loss: 0.4719 - val_loss: 166.5622\n",
            "Epoch 398/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 1.5375 - val_loss: 168.5860\n",
            "Epoch 399/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 4.7560 - val_loss: 165.9633\n",
            "Epoch 400/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 10.7510 - val_loss: 163.5569\n",
            "Epoch 401/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 3.8533 - val_loss: 167.6304\n",
            "Epoch 402/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 1.6694 - val_loss: 166.2819\n",
            "Epoch 403/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 1.1907 - val_loss: 166.4206\n",
            "Epoch 404/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.5715 - val_loss: 166.2406\n",
            "Epoch 405/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.3142 - val_loss: 166.0452\n",
            "Epoch 406/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.1650 - val_loss: 166.8349\n",
            "Epoch 407/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.2993 - val_loss: 166.6639\n",
            "Epoch 408/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.1991 - val_loss: 166.6753\n",
            "Epoch 409/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.2496 - val_loss: 166.6731\n",
            "Epoch 410/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.3698 - val_loss: 166.8290\n",
            "Epoch 411/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.5230 - val_loss: 167.7480\n",
            "Epoch 412/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.4792 - val_loss: 167.7301\n",
            "Epoch 413/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.6009 - val_loss: 168.4797\n",
            "Epoch 414/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 1.9292 - val_loss: 169.5183\n",
            "Epoch 415/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 1.3374 - val_loss: 168.3188\n",
            "Epoch 416/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.4800 - val_loss: 167.2051\n",
            "Epoch 417/1000\n",
            "1500/1500 [==============================] - 0s 102us/step - loss: 0.2924 - val_loss: 169.1256\n",
            "Epoch 418/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.1801 - val_loss: 167.3658\n",
            "Epoch 419/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.4797 - val_loss: 166.9900\n",
            "Epoch 420/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.6516 - val_loss: 167.6117\n",
            "Epoch 421/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 1.1346 - val_loss: 168.9873\n",
            "Epoch 422/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 1.1306 - val_loss: 166.2852\n",
            "Epoch 423/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 3.7875 - val_loss: 167.1425\n",
            "Epoch 424/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 3.8830 - val_loss: 170.7794\n",
            "Epoch 425/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 2.9136 - val_loss: 168.7183\n",
            "Epoch 426/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.7938 - val_loss: 166.9857\n",
            "Epoch 427/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.8142 - val_loss: 166.9744\n",
            "Epoch 428/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 1.7680 - val_loss: 165.7735\n",
            "Epoch 429/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 0.5962 - val_loss: 166.3956\n",
            "Epoch 430/1000\n",
            "1500/1500 [==============================] - 0s 102us/step - loss: 0.9487 - val_loss: 166.3882\n",
            "Epoch 431/1000\n",
            "1500/1500 [==============================] - 0s 121us/step - loss: 1.4953 - val_loss: 168.7885\n",
            "Epoch 432/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 1.2515 - val_loss: 165.9501\n",
            "Epoch 433/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.4672 - val_loss: 166.1198\n",
            "Epoch 434/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.5266 - val_loss: 166.2011\n",
            "Epoch 435/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.5557 - val_loss: 166.1530\n",
            "Epoch 436/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.2366 - val_loss: 166.7026\n",
            "Epoch 437/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.6995 - val_loss: 165.8662\n",
            "Epoch 438/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.4830 - val_loss: 165.8367\n",
            "Epoch 439/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.2884 - val_loss: 167.7706\n",
            "Epoch 440/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.6162 - val_loss: 167.4438\n",
            "Epoch 441/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 1.6558 - val_loss: 166.9753\n",
            "Epoch 442/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 1.1047 - val_loss: 167.3094\n",
            "Epoch 443/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.4485 - val_loss: 167.4640\n",
            "Epoch 444/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.6365 - val_loss: 168.1553\n",
            "Epoch 445/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.4423 - val_loss: 168.5076\n",
            "Epoch 446/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.7312 - val_loss: 168.8834\n",
            "Epoch 447/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.4198 - val_loss: 167.2433\n",
            "Epoch 448/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.3220 - val_loss: 166.0597\n",
            "Epoch 449/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.2651 - val_loss: 165.9603\n",
            "Epoch 450/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.2064 - val_loss: 166.4270\n",
            "Epoch 451/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.2113 - val_loss: 166.6950\n",
            "Epoch 452/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.1127 - val_loss: 166.5507\n",
            "Epoch 453/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.5776 - val_loss: 167.7870\n",
            "Epoch 454/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.9047 - val_loss: 168.7894\n",
            "Epoch 455/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 1.2228 - val_loss: 168.4183\n",
            "Epoch 456/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.5536 - val_loss: 165.8840\n",
            "Epoch 457/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 5.7089 - val_loss: 164.9083\n",
            "Epoch 458/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 2.5673 - val_loss: 170.0796\n",
            "Epoch 459/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 4.8208 - val_loss: 165.1407\n",
            "Epoch 460/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 3.3609 - val_loss: 164.8053\n",
            "Epoch 461/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.8395 - val_loss: 165.3371\n",
            "Epoch 462/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 1.2190 - val_loss: 165.9641\n",
            "Epoch 463/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.4693 - val_loss: 165.7442\n",
            "Epoch 464/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.5407 - val_loss: 165.0997\n",
            "Epoch 465/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 0.5031 - val_loss: 165.5297\n",
            "Epoch 466/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.6845 - val_loss: 165.9755\n",
            "Epoch 467/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.3053 - val_loss: 165.4682\n",
            "Epoch 468/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.1645 - val_loss: 166.2865\n",
            "Epoch 469/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.0894 - val_loss: 165.9678\n",
            "Epoch 470/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.0609 - val_loss: 165.5165\n",
            "Epoch 471/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 0.0470 - val_loss: 165.7842\n",
            "Epoch 472/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.0604 - val_loss: 165.9686\n",
            "Epoch 473/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.0540 - val_loss: 165.6495\n",
            "Epoch 474/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.0653 - val_loss: 165.7299\n",
            "Epoch 475/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.0714 - val_loss: 166.2769\n",
            "Epoch 476/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.1295 - val_loss: 166.3601\n",
            "Epoch 477/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.1727 - val_loss: 166.0550\n",
            "Epoch 478/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 2.6913 - val_loss: 163.8833\n",
            "Epoch 479/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 3.5735 - val_loss: 166.9811\n",
            "Epoch 480/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 4.1982 - val_loss: 166.5841\n",
            "Epoch 481/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.6990 - val_loss: 166.2969\n",
            "Epoch 482/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.6408 - val_loss: 166.6759\n",
            "Epoch 483/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.5652 - val_loss: 166.7945\n",
            "Epoch 484/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.9310 - val_loss: 165.4355\n",
            "Epoch 485/1000\n",
            "1500/1500 [==============================] - 0s 125us/step - loss: 0.6804 - val_loss: 164.0467\n",
            "Epoch 486/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.5567 - val_loss: 167.1430\n",
            "Epoch 487/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.4769 - val_loss: 165.8949\n",
            "Epoch 488/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.9290 - val_loss: 166.3312\n",
            "Epoch 489/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 0.4822 - val_loss: 166.3953\n",
            "Epoch 490/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.6827 - val_loss: 166.9140\n",
            "Epoch 491/1000\n",
            "1500/1500 [==============================] - 0s 117us/step - loss: 1.8152 - val_loss: 167.6250\n",
            "Epoch 492/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 3.1726 - val_loss: 166.2067\n",
            "Epoch 493/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 3.7477 - val_loss: 167.8519\n",
            "Epoch 494/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 4.0512 - val_loss: 172.7728\n",
            "Epoch 495/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 2.3478 - val_loss: 164.3495\n",
            "Epoch 496/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.8911 - val_loss: 164.7488\n",
            "Epoch 497/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.3723 - val_loss: 164.9839\n",
            "Epoch 498/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.3098 - val_loss: 166.9447\n",
            "Epoch 499/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.2575 - val_loss: 165.4813\n",
            "Epoch 500/1000\n",
            "1500/1500 [==============================] - 0s 118us/step - loss: 0.2902 - val_loss: 166.0266\n",
            "Epoch 501/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.1577 - val_loss: 165.9420\n",
            "Epoch 502/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.1247 - val_loss: 165.4203\n",
            "Epoch 503/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.6437 - val_loss: 166.6869\n",
            "Epoch 504/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.7128 - val_loss: 164.4525\n",
            "Epoch 505/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.3381 - val_loss: 165.7131\n",
            "Epoch 506/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.2840 - val_loss: 165.3374\n",
            "Epoch 507/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.2434 - val_loss: 165.5970\n",
            "Epoch 508/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.3127 - val_loss: 165.0269\n",
            "Epoch 509/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.4517 - val_loss: 165.6653\n",
            "Epoch 510/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.9956 - val_loss: 166.5256\n",
            "Epoch 511/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.7126 - val_loss: 165.2389\n",
            "Epoch 512/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 1.2435 - val_loss: 165.9644\n",
            "Epoch 513/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.7169 - val_loss: 164.6648\n",
            "Epoch 514/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.3140 - val_loss: 165.9339\n",
            "Epoch 515/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.4813 - val_loss: 165.5898\n",
            "Epoch 516/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.5943 - val_loss: 166.6872\n",
            "Epoch 517/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.5635 - val_loss: 166.0393\n",
            "Epoch 518/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.5698 - val_loss: 165.1746\n",
            "Epoch 519/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 1.1182 - val_loss: 167.0081\n",
            "Epoch 520/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 2.4026 - val_loss: 166.2527\n",
            "Epoch 521/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.6997 - val_loss: 167.2411\n",
            "Epoch 522/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.7745 - val_loss: 166.5739\n",
            "Epoch 523/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 0.8302 - val_loss: 170.9219\n",
            "Epoch 524/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 2.6078 - val_loss: 168.3884\n",
            "Epoch 525/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 2.5149 - val_loss: 166.2875\n",
            "Epoch 526/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 1.3816 - val_loss: 165.6928\n",
            "Epoch 527/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.5214 - val_loss: 165.9305\n",
            "Epoch 528/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.4445 - val_loss: 165.0962\n",
            "Epoch 529/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.4475 - val_loss: 165.5792\n",
            "Epoch 530/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.3433 - val_loss: 165.2157\n",
            "Epoch 531/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.4703 - val_loss: 165.9865\n",
            "Epoch 532/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 3.0415 - val_loss: 162.9246\n",
            "Epoch 533/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 1.2829 - val_loss: 165.2681\n",
            "Epoch 534/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.0407 - val_loss: 166.8632\n",
            "Epoch 535/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 1.1673 - val_loss: 165.0252\n",
            "Epoch 536/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 5.9762 - val_loss: 178.4613\n",
            "Epoch 537/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 4.5818 - val_loss: 163.1387\n",
            "Epoch 538/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 2.1281 - val_loss: 168.6347\n",
            "Epoch 539/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 4.0027 - val_loss: 164.2043\n",
            "Epoch 540/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 1.0465 - val_loss: 166.0976\n",
            "Epoch 541/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.6606 - val_loss: 165.2777\n",
            "Epoch 542/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.5716 - val_loss: 165.3100\n",
            "Epoch 543/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.3151 - val_loss: 165.4929\n",
            "Epoch 544/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.2681 - val_loss: 165.0822\n",
            "Epoch 545/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.2403 - val_loss: 166.2768\n",
            "Epoch 546/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.2874 - val_loss: 165.2774\n",
            "Epoch 547/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.1780 - val_loss: 165.9621\n",
            "Epoch 548/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.0991 - val_loss: 165.3234\n",
            "Epoch 549/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.0506 - val_loss: 165.0970\n",
            "Epoch 550/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.1620 - val_loss: 165.7107\n",
            "Epoch 551/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.1128 - val_loss: 166.1216\n",
            "Epoch 552/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.1027 - val_loss: 165.3726\n",
            "Epoch 553/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.0846 - val_loss: 165.1996\n",
            "Epoch 554/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.0676 - val_loss: 165.5860\n",
            "Epoch 555/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.0573 - val_loss: 165.4853\n",
            "Epoch 556/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.0735 - val_loss: 165.4359\n",
            "Epoch 557/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.0587 - val_loss: 166.0988\n",
            "Epoch 558/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.0960 - val_loss: 165.0685\n",
            "Epoch 559/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.2781 - val_loss: 165.7827\n",
            "Epoch 560/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 1.8861 - val_loss: 166.2479\n",
            "Epoch 561/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 3.4433 - val_loss: 164.7067\n",
            "Epoch 562/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.5615 - val_loss: 164.4090\n",
            "Epoch 563/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.9722 - val_loss: 165.8677\n",
            "Epoch 564/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 2.1050 - val_loss: 165.1130\n",
            "Epoch 565/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 3.0467 - val_loss: 169.0301\n",
            "Epoch 566/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 3.1791 - val_loss: 164.7558\n",
            "Epoch 567/1000\n",
            "1500/1500 [==============================] - 0s 120us/step - loss: 1.2283 - val_loss: 163.5310\n",
            "Epoch 568/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 1.5573 - val_loss: 164.0585\n",
            "Epoch 569/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 2.0527 - val_loss: 166.6488\n",
            "Epoch 570/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 4.0443 - val_loss: 164.2314\n",
            "Epoch 571/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 2.4512 - val_loss: 166.5854\n",
            "Epoch 572/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.9848 - val_loss: 164.0042\n",
            "Epoch 573/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.5292 - val_loss: 163.7435\n",
            "Epoch 574/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.3024 - val_loss: 164.4978\n",
            "Epoch 575/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.3033 - val_loss: 165.1275\n",
            "Epoch 576/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.2188 - val_loss: 165.3119\n",
            "Epoch 577/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.2432 - val_loss: 164.5425\n",
            "Epoch 578/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.7161 - val_loss: 164.9092\n",
            "Epoch 579/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.3415 - val_loss: 164.4763\n",
            "Epoch 580/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.1819 - val_loss: 165.1094\n",
            "Epoch 581/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.0877 - val_loss: 165.6154\n",
            "Epoch 582/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.0835 - val_loss: 165.0927\n",
            "Epoch 583/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.5799 - val_loss: 169.3817\n",
            "Epoch 584/1000\n",
            "1500/1500 [==============================] - 0s 102us/step - loss: 1.7839 - val_loss: 164.4741\n",
            "Epoch 585/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 1.3279 - val_loss: 165.0270\n",
            "Epoch 586/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 4.0001 - val_loss: 165.1051\n",
            "Epoch 587/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 2.1220 - val_loss: 167.1096\n",
            "Epoch 588/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 1.1175 - val_loss: 166.0106\n",
            "Epoch 589/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.8814 - val_loss: 165.4251\n",
            "Epoch 590/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.7588 - val_loss: 164.7618\n",
            "Epoch 591/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.9358 - val_loss: 165.8896\n",
            "Epoch 592/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.3051 - val_loss: 166.7164\n",
            "Epoch 593/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.3415 - val_loss: 166.0230\n",
            "Epoch 594/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.1121 - val_loss: 165.9558\n",
            "Epoch 595/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.1390 - val_loss: 164.8699\n",
            "Epoch 596/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.4564 - val_loss: 165.8628\n",
            "Epoch 597/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.1939 - val_loss: 165.1448\n",
            "Epoch 598/1000\n",
            "1500/1500 [==============================] - 0s 119us/step - loss: 0.1012 - val_loss: 164.8431\n",
            "Epoch 599/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 0.1291 - val_loss: 165.5318\n",
            "Epoch 600/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.1614 - val_loss: 164.8604\n",
            "Epoch 601/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.1510 - val_loss: 165.1756\n",
            "Epoch 602/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.2857 - val_loss: 166.1317\n",
            "Epoch 603/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.8117 - val_loss: 164.8554\n",
            "Epoch 604/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 1.9867 - val_loss: 164.2688\n",
            "Epoch 605/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 1.4033 - val_loss: 165.7454\n",
            "Epoch 606/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.6400 - val_loss: 164.4323\n",
            "Epoch 607/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 1.1165 - val_loss: 170.5373\n",
            "Epoch 608/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 1.4441 - val_loss: 163.8988\n",
            "Epoch 609/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 1.2111 - val_loss: 164.6630\n",
            "Epoch 610/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 1.3603 - val_loss: 164.9735\n",
            "Epoch 611/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.5795 - val_loss: 164.6065\n",
            "Epoch 612/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.3104 - val_loss: 164.6339\n",
            "Epoch 613/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.2712 - val_loss: 164.2957\n",
            "Epoch 614/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.2959 - val_loss: 163.3061\n",
            "Epoch 615/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.2866 - val_loss: 165.4665\n",
            "Epoch 616/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.6329 - val_loss: 163.0750\n",
            "Epoch 617/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.3740 - val_loss: 165.2063\n",
            "Epoch 618/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.0988 - val_loss: 166.5260\n",
            "Epoch 619/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 4.5865 - val_loss: 167.1666\n",
            "Epoch 620/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 5.2065 - val_loss: 163.9846\n",
            "Epoch 621/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 2.1955 - val_loss: 165.9412\n",
            "Epoch 622/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 1.9635 - val_loss: 164.8341\n",
            "Epoch 623/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 2.4346 - val_loss: 163.4239\n",
            "Epoch 624/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.3861 - val_loss: 165.8241\n",
            "Epoch 625/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 4.1378 - val_loss: 163.3408\n",
            "Epoch 626/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 1.8510 - val_loss: 164.7577\n",
            "Epoch 627/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.6950 - val_loss: 164.1972\n",
            "Epoch 628/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.2932 - val_loss: 163.8009\n",
            "Epoch 629/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.2025 - val_loss: 163.2848\n",
            "Epoch 630/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.2135 - val_loss: 163.8701\n",
            "Epoch 631/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.1721 - val_loss: 163.2935\n",
            "Epoch 632/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.1857 - val_loss: 163.7466\n",
            "Epoch 633/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.1348 - val_loss: 163.1027\n",
            "Epoch 634/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.0967 - val_loss: 163.7213\n",
            "Epoch 635/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.1344 - val_loss: 163.3643\n",
            "Epoch 636/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.0769 - val_loss: 163.7626\n",
            "Epoch 637/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.0449 - val_loss: 163.8790\n",
            "Epoch 638/1000\n",
            "1500/1500 [==============================] - 0s 116us/step - loss: 0.0592 - val_loss: 164.0425\n",
            "Epoch 639/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.0420 - val_loss: 164.1796\n",
            "Epoch 640/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.0264 - val_loss: 164.1635\n",
            "Epoch 641/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.0574 - val_loss: 163.9196\n",
            "Epoch 642/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.6269 - val_loss: 166.3435\n",
            "Epoch 643/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 1.0856 - val_loss: 163.8137\n",
            "Epoch 644/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.4111 - val_loss: 163.5637\n",
            "Epoch 645/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.4986 - val_loss: 164.6392\n",
            "Epoch 646/1000\n",
            "1500/1500 [==============================] - 0s 101us/step - loss: 0.9588 - val_loss: 166.6686\n",
            "Epoch 647/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 1.7204 - val_loss: 163.7156\n",
            "Epoch 648/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.6410 - val_loss: 164.6774\n",
            "Epoch 649/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.2714 - val_loss: 162.9423\n",
            "Epoch 650/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.2502 - val_loss: 163.8752\n",
            "Epoch 651/1000\n",
            "1500/1500 [==============================] - 0s 117us/step - loss: 0.4301 - val_loss: 164.4258\n",
            "Epoch 652/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 0.6467 - val_loss: 166.4961\n",
            "Epoch 653/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 1.0932 - val_loss: 164.9139\n",
            "Epoch 654/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 1.2638 - val_loss: 164.4534\n",
            "Epoch 655/1000\n",
            "1500/1500 [==============================] - 0s 126us/step - loss: 2.8509 - val_loss: 167.0907\n",
            "Epoch 656/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 1.8800 - val_loss: 166.7673\n",
            "Epoch 657/1000\n",
            "1500/1500 [==============================] - 0s 116us/step - loss: 3.6535 - val_loss: 165.9442\n",
            "Epoch 658/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 1.4663 - val_loss: 163.9656\n",
            "Epoch 659/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.8217 - val_loss: 162.0084\n",
            "Epoch 660/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.7841 - val_loss: 163.6983\n",
            "Epoch 661/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.5238 - val_loss: 163.9088\n",
            "Epoch 662/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.6172 - val_loss: 163.9931\n",
            "Epoch 663/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.8742 - val_loss: 166.5213\n",
            "Epoch 664/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 2.6196 - val_loss: 164.4477\n",
            "Epoch 665/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 1.1797 - val_loss: 163.3504\n",
            "Epoch 666/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.5013 - val_loss: 163.8996\n",
            "Epoch 667/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 0.5057 - val_loss: 163.7059\n",
            "Epoch 668/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.4378 - val_loss: 164.3351\n",
            "Epoch 669/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.4567 - val_loss: 163.6114\n",
            "Epoch 670/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.2692 - val_loss: 163.6524\n",
            "Epoch 671/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.2279 - val_loss: 164.1025\n",
            "Epoch 672/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.3368 - val_loss: 165.1684\n",
            "Epoch 673/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 0.5853 - val_loss: 164.6511\n",
            "Epoch 674/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.7908 - val_loss: 163.2505\n",
            "Epoch 675/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 1.2578 - val_loss: 164.1290\n",
            "Epoch 676/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.4464 - val_loss: 164.8109\n",
            "Epoch 677/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.4937 - val_loss: 164.4346\n",
            "Epoch 678/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.7953 - val_loss: 162.7419\n",
            "Epoch 679/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 1.6587 - val_loss: 164.0996\n",
            "Epoch 680/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 2.8056 - val_loss: 165.4429\n",
            "Epoch 681/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 2.8982 - val_loss: 161.4742\n",
            "Epoch 682/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.9363 - val_loss: 162.3633\n",
            "Epoch 683/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 1.3658 - val_loss: 163.5449\n",
            "Epoch 684/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.6445 - val_loss: 163.2839\n",
            "Epoch 685/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.2749 - val_loss: 163.0340\n",
            "Epoch 686/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.2303 - val_loss: 163.8634\n",
            "Epoch 687/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.3370 - val_loss: 163.6908\n",
            "Epoch 688/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 1.1595 - val_loss: 162.9072\n",
            "Epoch 689/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.6017 - val_loss: 164.4105\n",
            "Epoch 690/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.4677 - val_loss: 163.7517\n",
            "Epoch 691/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.3244 - val_loss: 163.6859\n",
            "Epoch 692/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.2634 - val_loss: 163.8523\n",
            "Epoch 693/1000\n",
            "1500/1500 [==============================] - 0s 120us/step - loss: 1.0079 - val_loss: 162.9172\n",
            "Epoch 694/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.4750 - val_loss: 162.7955\n",
            "Epoch 695/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.6037 - val_loss: 163.5959\n",
            "Epoch 696/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 1.2457 - val_loss: 163.5662\n",
            "Epoch 697/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 1.2862 - val_loss: 164.4261\n",
            "Epoch 698/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 2.9022 - val_loss: 161.3896\n",
            "Epoch 699/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 2.4646 - val_loss: 163.0962\n",
            "Epoch 700/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 2.2865 - val_loss: 163.6854\n",
            "Epoch 701/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.1460 - val_loss: 163.7762\n",
            "Epoch 702/1000\n",
            "1500/1500 [==============================] - 0s 117us/step - loss: 1.1608 - val_loss: 163.1463\n",
            "Epoch 703/1000\n",
            "1500/1500 [==============================] - 0s 116us/step - loss: 0.4345 - val_loss: 163.5431\n",
            "Epoch 704/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.5369 - val_loss: 163.2969\n",
            "Epoch 705/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.4988 - val_loss: 162.9912\n",
            "Epoch 706/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.4142 - val_loss: 162.2364\n",
            "Epoch 707/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.3760 - val_loss: 161.9897\n",
            "Epoch 708/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.3571 - val_loss: 164.2997\n",
            "Epoch 709/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.4514 - val_loss: 163.9971\n",
            "Epoch 710/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.2280 - val_loss: 163.2551\n",
            "Epoch 711/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.1054 - val_loss: 163.1113\n",
            "Epoch 712/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.0594 - val_loss: 163.1309\n",
            "Epoch 713/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.0738 - val_loss: 162.6519\n",
            "Epoch 714/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.1926 - val_loss: 162.8337\n",
            "Epoch 715/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.1798 - val_loss: 162.4825\n",
            "Epoch 716/1000\n",
            "1500/1500 [==============================] - 0s 118us/step - loss: 0.1082 - val_loss: 163.0615\n",
            "Epoch 717/1000\n",
            "1500/1500 [==============================] - 0s 117us/step - loss: 0.5438 - val_loss: 163.2066\n",
            "Epoch 718/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.5718 - val_loss: 164.9469\n",
            "Epoch 719/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.8548 - val_loss: 162.9346\n",
            "Epoch 720/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 1.0424 - val_loss: 164.3991\n",
            "Epoch 721/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 2.0119 - val_loss: 164.7981\n",
            "Epoch 722/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 2.5829 - val_loss: 161.3238\n",
            "Epoch 723/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 2.1242 - val_loss: 166.2078\n",
            "Epoch 724/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 1.5141 - val_loss: 162.4282\n",
            "Epoch 725/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 1.0513 - val_loss: 162.5552\n",
            "Epoch 726/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.7442 - val_loss: 163.4832\n",
            "Epoch 727/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 0.4038 - val_loss: 162.7471\n",
            "Epoch 728/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.3013 - val_loss: 162.3530\n",
            "Epoch 729/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.3434 - val_loss: 163.5287\n",
            "Epoch 730/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.8348 - val_loss: 162.9549\n",
            "Epoch 731/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.9856 - val_loss: 165.9156\n",
            "Epoch 732/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.1435 - val_loss: 163.6553\n",
            "Epoch 733/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.8973 - val_loss: 165.2947\n",
            "Epoch 734/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.8297 - val_loss: 163.5700\n",
            "Epoch 735/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.4398 - val_loss: 163.0689\n",
            "Epoch 736/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.2852 - val_loss: 164.2352\n",
            "Epoch 737/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.6830 - val_loss: 162.1725\n",
            "Epoch 738/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.9408 - val_loss: 162.1868\n",
            "Epoch 739/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.3633 - val_loss: 163.5196\n",
            "Epoch 740/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.3084 - val_loss: 163.2972\n",
            "Epoch 741/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.2789 - val_loss: 161.9742\n",
            "Epoch 742/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.1752 - val_loss: 162.5488\n",
            "Epoch 743/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.6827 - val_loss: 164.1466\n",
            "Epoch 744/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.8216 - val_loss: 163.0045\n",
            "Epoch 745/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 4.8995 - val_loss: 168.6812\n",
            "Epoch 746/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 11.1189 - val_loss: 162.3977\n",
            "Epoch 747/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 4.6048 - val_loss: 163.1094\n",
            "Epoch 748/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 3.7287 - val_loss: 162.2387\n",
            "Epoch 749/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 1.5274 - val_loss: 162.3210\n",
            "Epoch 750/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 1.2145 - val_loss: 160.8181\n",
            "Epoch 751/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.7482 - val_loss: 160.1777\n",
            "Epoch 752/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.4352 - val_loss: 161.7715\n",
            "Epoch 753/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.2285 - val_loss: 162.1395\n",
            "Epoch 754/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.2143 - val_loss: 161.7191\n",
            "Epoch 755/1000\n",
            "1500/1500 [==============================] - 0s 101us/step - loss: 0.1389 - val_loss: 161.3985\n",
            "Epoch 756/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.1205 - val_loss: 161.9821\n",
            "Epoch 757/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.1468 - val_loss: 161.5904\n",
            "Epoch 758/1000\n",
            "1500/1500 [==============================] - 0s 134us/step - loss: 0.0671 - val_loss: 161.6103\n",
            "Epoch 759/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 0.0619 - val_loss: 161.6819\n",
            "Epoch 760/1000\n",
            "1500/1500 [==============================] - 0s 119us/step - loss: 0.1152 - val_loss: 161.6312\n",
            "Epoch 761/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.0620 - val_loss: 161.5674\n",
            "Epoch 762/1000\n",
            "1500/1500 [==============================] - 0s 116us/step - loss: 0.1895 - val_loss: 161.6532\n",
            "Epoch 763/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.2803 - val_loss: 161.5818\n",
            "Epoch 764/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 0.1325 - val_loss: 162.0515\n",
            "Epoch 765/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.2861 - val_loss: 162.4582\n",
            "Epoch 766/1000\n",
            "1500/1500 [==============================] - 0s 129us/step - loss: 0.1698 - val_loss: 162.1976\n",
            "Epoch 767/1000\n",
            "1500/1500 [==============================] - 0s 119us/step - loss: 0.1559 - val_loss: 161.6829\n",
            "Epoch 768/1000\n",
            "1500/1500 [==============================] - 0s 116us/step - loss: 0.1281 - val_loss: 161.7270\n",
            "Epoch 769/1000\n",
            "1500/1500 [==============================] - 0s 118us/step - loss: 0.0816 - val_loss: 161.4652\n",
            "Epoch 770/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.0947 - val_loss: 161.6346\n",
            "Epoch 771/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.0609 - val_loss: 161.9336\n",
            "Epoch 772/1000\n",
            "1500/1500 [==============================] - 0s 127us/step - loss: 0.1031 - val_loss: 161.5393\n",
            "Epoch 773/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.2959 - val_loss: 161.9128\n",
            "Epoch 774/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.1710 - val_loss: 161.5608\n",
            "Epoch 775/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.1099 - val_loss: 161.5309\n",
            "Epoch 776/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.2284 - val_loss: 162.7188\n",
            "Epoch 777/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 6.5515 - val_loss: 159.4365\n",
            "Epoch 778/1000\n",
            "1500/1500 [==============================] - 0s 119us/step - loss: 11.1504 - val_loss: 162.5913\n",
            "Epoch 779/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 4.9287 - val_loss: 161.4395\n",
            "Epoch 780/1000\n",
            "1500/1500 [==============================] - 0s 117us/step - loss: 1.5149 - val_loss: 158.8412\n",
            "Epoch 781/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 0.6385 - val_loss: 162.2043\n",
            "Epoch 782/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.4422 - val_loss: 160.7279\n",
            "Epoch 783/1000\n",
            "1500/1500 [==============================] - 0s 123us/step - loss: 0.4648 - val_loss: 161.1419\n",
            "Epoch 784/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.6064 - val_loss: 160.9631\n",
            "Epoch 785/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 0.2101 - val_loss: 160.6488\n",
            "Epoch 786/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.1602 - val_loss: 161.1645\n",
            "Epoch 787/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.1035 - val_loss: 160.9535\n",
            "Epoch 788/1000\n",
            "1500/1500 [==============================] - 0s 117us/step - loss: 0.1185 - val_loss: 160.8938\n",
            "Epoch 789/1000\n",
            "1500/1500 [==============================] - 0s 124us/step - loss: 0.1061 - val_loss: 160.7670\n",
            "Epoch 790/1000\n",
            "1500/1500 [==============================] - 0s 118us/step - loss: 0.0816 - val_loss: 161.4358\n",
            "Epoch 791/1000\n",
            "1500/1500 [==============================] - 0s 120us/step - loss: 0.0787 - val_loss: 161.5617\n",
            "Epoch 792/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 0.0888 - val_loss: 161.4321\n",
            "Epoch 793/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.0567 - val_loss: 161.4058\n",
            "Epoch 794/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.0452 - val_loss: 161.2931\n",
            "Epoch 795/1000\n",
            "1500/1500 [==============================] - 0s 118us/step - loss: 0.0768 - val_loss: 161.3387\n",
            "Epoch 796/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.0948 - val_loss: 161.3400\n",
            "Epoch 797/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 0.0814 - val_loss: 161.1079\n",
            "Epoch 798/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.1676 - val_loss: 161.2171\n",
            "Epoch 799/1000\n",
            "1500/1500 [==============================] - 0s 117us/step - loss: 0.2034 - val_loss: 161.4415\n",
            "Epoch 800/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.3411 - val_loss: 162.1045\n",
            "Epoch 801/1000\n",
            "1500/1500 [==============================] - 0s 116us/step - loss: 0.8962 - val_loss: 160.7596\n",
            "Epoch 802/1000\n",
            "1500/1500 [==============================] - 0s 120us/step - loss: 0.5759 - val_loss: 161.7400\n",
            "Epoch 803/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.9145 - val_loss: 162.1756\n",
            "Epoch 804/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.7507 - val_loss: 161.7602\n",
            "Epoch 805/1000\n",
            "1500/1500 [==============================] - 0s 117us/step - loss: 0.9780 - val_loss: 163.1580\n",
            "Epoch 806/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 2.5905 - val_loss: 165.9911\n",
            "Epoch 807/1000\n",
            "1500/1500 [==============================] - 0s 116us/step - loss: 3.6148 - val_loss: 159.6527\n",
            "Epoch 808/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 3.2685 - val_loss: 162.2644\n",
            "Epoch 809/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 2.4471 - val_loss: 162.4855\n",
            "Epoch 810/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 1.4988 - val_loss: 163.2172\n",
            "Epoch 811/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 1.4968 - val_loss: 160.5277\n",
            "Epoch 812/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 1.5126 - val_loss: 160.9479\n",
            "Epoch 813/1000\n",
            "1500/1500 [==============================] - 0s 116us/step - loss: 0.7800 - val_loss: 160.3566\n",
            "Epoch 814/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.2816 - val_loss: 161.5236\n",
            "Epoch 815/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.2190 - val_loss: 161.9779\n",
            "Epoch 816/1000\n",
            "1500/1500 [==============================] - 0s 117us/step - loss: 0.1765 - val_loss: 161.7736\n",
            "Epoch 817/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.1935 - val_loss: 161.6515\n",
            "Epoch 818/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.1416 - val_loss: 160.9864\n",
            "Epoch 819/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.1933 - val_loss: 161.8792\n",
            "Epoch 820/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.2049 - val_loss: 162.1027\n",
            "Epoch 821/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.1960 - val_loss: 161.6074\n",
            "Epoch 822/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.6924 - val_loss: 161.1190\n",
            "Epoch 823/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.5186 - val_loss: 161.9977\n",
            "Epoch 824/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.5597 - val_loss: 161.0057\n",
            "Epoch 825/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.5170 - val_loss: 161.0119\n",
            "Epoch 826/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 1.0587 - val_loss: 162.6989\n",
            "Epoch 827/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 1.0392 - val_loss: 162.6467\n",
            "Epoch 828/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 3.6043 - val_loss: 160.4847\n",
            "Epoch 829/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 1.4034 - val_loss: 162.1200\n",
            "Epoch 830/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 1.0427 - val_loss: 161.0413\n",
            "Epoch 831/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.9157 - val_loss: 160.5711\n",
            "Epoch 832/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.5775 - val_loss: 162.3278\n",
            "Epoch 833/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.3445 - val_loss: 161.5686\n",
            "Epoch 834/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.2945 - val_loss: 161.2972\n",
            "Epoch 835/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.1971 - val_loss: 162.0248\n",
            "Epoch 836/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.1094 - val_loss: 161.2562\n",
            "Epoch 837/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.1599 - val_loss: 160.8566\n",
            "Epoch 838/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.3734 - val_loss: 160.7457\n",
            "Epoch 839/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.1838 - val_loss: 160.5872\n",
            "Epoch 840/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.1282 - val_loss: 160.5760\n",
            "Epoch 841/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.1406 - val_loss: 160.7082\n",
            "Epoch 842/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.1204 - val_loss: 161.3445\n",
            "Epoch 843/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.2889 - val_loss: 159.9718\n",
            "Epoch 844/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.3615 - val_loss: 161.9680\n",
            "Epoch 845/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.3483 - val_loss: 160.0336\n",
            "Epoch 846/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.2054 - val_loss: 161.0195\n",
            "Epoch 847/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.2560 - val_loss: 161.8496\n",
            "Epoch 848/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.5571 - val_loss: 161.1996\n",
            "Epoch 849/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.5001 - val_loss: 161.0782\n",
            "Epoch 850/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.8249 - val_loss: 161.2523\n",
            "Epoch 851/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.8861 - val_loss: 162.0011\n",
            "Epoch 852/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.8602 - val_loss: 164.4414\n",
            "Epoch 853/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 1.5209 - val_loss: 160.5436\n",
            "Epoch 854/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.8274 - val_loss: 162.1792\n",
            "Epoch 855/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.2458 - val_loss: 161.2638\n",
            "Epoch 856/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.6841 - val_loss: 161.9644\n",
            "Epoch 857/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.6841 - val_loss: 160.4989\n",
            "Epoch 858/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 1.3638 - val_loss: 160.6455\n",
            "Epoch 859/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 2.2329 - val_loss: 163.0758\n",
            "Epoch 860/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 1.6355 - val_loss: 161.3768\n",
            "Epoch 861/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.7081 - val_loss: 160.7358\n",
            "Epoch 862/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.6696 - val_loss: 162.0422\n",
            "Epoch 863/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.7682 - val_loss: 161.3738\n",
            "Epoch 864/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.3811 - val_loss: 161.7289\n",
            "Epoch 865/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.6223 - val_loss: 161.7067\n",
            "Epoch 866/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 1.1172 - val_loss: 162.0903\n",
            "Epoch 867/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 2.4522 - val_loss: 162.4254\n",
            "Epoch 868/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 1.3502 - val_loss: 161.3841\n",
            "Epoch 869/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.4762 - val_loss: 160.4639\n",
            "Epoch 870/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.6012 - val_loss: 160.0687\n",
            "Epoch 871/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.4437 - val_loss: 159.4500\n",
            "Epoch 872/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.3692 - val_loss: 160.5106\n",
            "Epoch 873/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.3713 - val_loss: 159.5266\n",
            "Epoch 874/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.7418 - val_loss: 160.9523\n",
            "Epoch 875/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.9057 - val_loss: 160.7759\n",
            "Epoch 876/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.6704 - val_loss: 158.6272\n",
            "Epoch 877/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 2.4642 - val_loss: 162.7691\n",
            "Epoch 878/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 1.2473 - val_loss: 161.0888\n",
            "Epoch 879/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 1.4877 - val_loss: 161.4413\n",
            "Epoch 880/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.7669 - val_loss: 159.6929\n",
            "Epoch 881/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.8044 - val_loss: 160.5819\n",
            "Epoch 882/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 1.2583 - val_loss: 160.6787\n",
            "Epoch 883/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.8282 - val_loss: 160.2389\n",
            "Epoch 884/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.3678 - val_loss: 160.2774\n",
            "Epoch 885/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.3239 - val_loss: 159.1972\n",
            "Epoch 886/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.2355 - val_loss: 160.2437\n",
            "Epoch 887/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.1116 - val_loss: 159.8434\n",
            "Epoch 888/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.1051 - val_loss: 159.9276\n",
            "Epoch 889/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.0854 - val_loss: 160.4734\n",
            "Epoch 890/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.0902 - val_loss: 160.5734\n",
            "Epoch 891/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.0689 - val_loss: 159.9745\n",
            "Epoch 892/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.0453 - val_loss: 159.9864\n",
            "Epoch 893/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.0622 - val_loss: 160.2331\n",
            "Epoch 894/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.0964 - val_loss: 159.9220\n",
            "Epoch 895/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.3339 - val_loss: 162.2495\n",
            "Epoch 896/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 2.7145 - val_loss: 159.3595\n",
            "Epoch 897/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 4.8885 - val_loss: 165.8211\n",
            "Epoch 898/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 5.0017 - val_loss: 159.4098\n",
            "Epoch 899/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 2.0320 - val_loss: 160.9645\n",
            "Epoch 900/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 2.1225 - val_loss: 160.9790\n",
            "Epoch 901/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.7906 - val_loss: 159.8446\n",
            "Epoch 902/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.4649 - val_loss: 160.2648\n",
            "Epoch 903/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.2863 - val_loss: 160.1123\n",
            "Epoch 904/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.4669 - val_loss: 159.2271\n",
            "Epoch 905/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.2628 - val_loss: 159.5730\n",
            "Epoch 906/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.1744 - val_loss: 160.1274\n",
            "Epoch 907/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.2471 - val_loss: 160.0581\n",
            "Epoch 908/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.1957 - val_loss: 160.1940\n",
            "Epoch 909/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.1049 - val_loss: 159.2847\n",
            "Epoch 910/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 0.0623 - val_loss: 159.9590\n",
            "Epoch 911/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.0654 - val_loss: 159.4170\n",
            "Epoch 912/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.0829 - val_loss: 159.7969\n",
            "Epoch 913/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.1619 - val_loss: 160.8047\n",
            "Epoch 914/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.2864 - val_loss: 160.6920\n",
            "Epoch 915/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.4980 - val_loss: 159.9333\n",
            "Epoch 916/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.6364 - val_loss: 160.9523\n",
            "Epoch 917/1000\n",
            "1500/1500 [==============================] - 0s 102us/step - loss: 0.8262 - val_loss: 160.4962\n",
            "Epoch 918/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.4371 - val_loss: 159.6238\n",
            "Epoch 919/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.5081 - val_loss: 159.5591\n",
            "Epoch 920/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 0.9082 - val_loss: 160.3046\n",
            "Epoch 921/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 1.6820 - val_loss: 170.4684\n",
            "Epoch 922/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 3.6549 - val_loss: 164.1817\n",
            "Epoch 923/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 4.8837 - val_loss: 160.0680\n",
            "Epoch 924/1000\n",
            "1500/1500 [==============================] - 0s 102us/step - loss: 5.8680 - val_loss: 158.4162\n",
            "Epoch 925/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 4.0777 - val_loss: 160.4895\n",
            "Epoch 926/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 2.1315 - val_loss: 159.1493\n",
            "Epoch 927/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.7417 - val_loss: 158.6496\n",
            "Epoch 928/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.4176 - val_loss: 158.8705\n",
            "Epoch 929/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.4159 - val_loss: 159.3657\n",
            "Epoch 930/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.1724 - val_loss: 159.5533\n",
            "Epoch 931/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.0988 - val_loss: 159.7026\n",
            "Epoch 932/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.0742 - val_loss: 159.7288\n",
            "Epoch 933/1000\n",
            "1500/1500 [==============================] - 0s 108us/step - loss: 0.1073 - val_loss: 160.1773\n",
            "Epoch 934/1000\n",
            "1500/1500 [==============================] - 0s 102us/step - loss: 0.0805 - val_loss: 159.6204\n",
            "Epoch 935/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.0482 - val_loss: 159.8820\n",
            "Epoch 936/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.0586 - val_loss: 160.0531\n",
            "Epoch 937/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.0470 - val_loss: 159.9608\n",
            "Epoch 938/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.0523 - val_loss: 159.6901\n",
            "Epoch 939/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.0516 - val_loss: 159.7301\n",
            "Epoch 940/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.0329 - val_loss: 160.4020\n",
            "Epoch 941/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.0395 - val_loss: 159.9487\n",
            "Epoch 942/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.0395 - val_loss: 160.1713\n",
            "Epoch 943/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.1090 - val_loss: 159.9279\n",
            "Epoch 944/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.2871 - val_loss: 161.2047\n",
            "Epoch 945/1000\n",
            "1500/1500 [==============================] - 0s 110us/step - loss: 0.6788 - val_loss: 160.5879\n",
            "Epoch 946/1000\n",
            "1500/1500 [==============================] - 0s 112us/step - loss: 0.7547 - val_loss: 161.7806\n",
            "Epoch 947/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.6462 - val_loss: 160.1945\n",
            "Epoch 948/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.5601 - val_loss: 161.1522\n",
            "Epoch 949/1000\n",
            "1500/1500 [==============================] - 0s 102us/step - loss: 0.4525 - val_loss: 159.6806\n",
            "Epoch 950/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.2638 - val_loss: 159.3147\n",
            "Epoch 951/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.3206 - val_loss: 159.8406\n",
            "Epoch 952/1000\n",
            "1500/1500 [==============================] - 0s 115us/step - loss: 0.4576 - val_loss: 160.4064\n",
            "Epoch 953/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.4417 - val_loss: 159.3637\n",
            "Epoch 954/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.5774 - val_loss: 159.8643\n",
            "Epoch 955/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.9536 - val_loss: 159.6468\n",
            "Epoch 956/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 4.8017 - val_loss: 155.3449\n",
            "Epoch 957/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 2.8225 - val_loss: 158.6004\n",
            "Epoch 958/1000\n",
            "1500/1500 [==============================] - 0s 119us/step - loss: 1.4012 - val_loss: 159.8321\n",
            "Epoch 959/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.9446 - val_loss: 158.8934\n",
            "Epoch 960/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.5958 - val_loss: 158.8088\n",
            "Epoch 961/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.3736 - val_loss: 158.7991\n",
            "Epoch 962/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.5491 - val_loss: 158.2144\n",
            "Epoch 963/1000\n",
            "1500/1500 [==============================] - 0s 111us/step - loss: 0.1810 - val_loss: 159.1712\n",
            "Epoch 964/1000\n",
            "1500/1500 [==============================] - 0s 119us/step - loss: 0.1132 - val_loss: 159.0015\n",
            "Epoch 965/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.0612 - val_loss: 158.7875\n",
            "Epoch 966/1000\n",
            "1500/1500 [==============================] - 0s 129us/step - loss: 0.0910 - val_loss: 158.9946\n",
            "Epoch 967/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.4545 - val_loss: 159.6932\n",
            "Epoch 968/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.3174 - val_loss: 158.8558\n",
            "Epoch 969/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.2322 - val_loss: 159.3246\n",
            "Epoch 970/1000\n",
            "1500/1500 [==============================] - 0s 113us/step - loss: 0.1879 - val_loss: 158.9531\n",
            "Epoch 971/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.6885 - val_loss: 159.0096\n",
            "Epoch 972/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 0.9548 - val_loss: 158.4097\n",
            "Epoch 973/1000\n",
            "1500/1500 [==============================] - 0s 102us/step - loss: 0.7114 - val_loss: 159.7776\n",
            "Epoch 974/1000\n",
            "1500/1500 [==============================] - 0s 102us/step - loss: 0.6608 - val_loss: 159.3844\n",
            "Epoch 975/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 1.0357 - val_loss: 158.2215\n",
            "Epoch 976/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.6590 - val_loss: 158.4894\n",
            "Epoch 977/1000\n",
            "1500/1500 [==============================] - 0s 117us/step - loss: 1.2152 - val_loss: 160.0464\n",
            "Epoch 978/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 1.2556 - val_loss: 162.0393\n",
            "Epoch 979/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 1.1631 - val_loss: 160.8247\n",
            "Epoch 980/1000\n",
            "1500/1500 [==============================] - 0s 102us/step - loss: 0.8445 - val_loss: 158.0065\n",
            "Epoch 981/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.6390 - val_loss: 159.5083\n",
            "Epoch 982/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.3747 - val_loss: 158.9662\n",
            "Epoch 983/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.3265 - val_loss: 159.2167\n",
            "Epoch 984/1000\n",
            "1500/1500 [==============================] - 0s 102us/step - loss: 2.2706 - val_loss: 159.2629\n",
            "Epoch 985/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 2.6341 - val_loss: 159.4139\n",
            "Epoch 986/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 2.4826 - val_loss: 159.1215\n",
            "Epoch 987/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 1.2009 - val_loss: 159.7606\n",
            "Epoch 988/1000\n",
            "1500/1500 [==============================] - 0s 104us/step - loss: 2.1731 - val_loss: 162.1663\n",
            "Epoch 989/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 2.9920 - val_loss: 156.2310\n",
            "Epoch 990/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 1.0265 - val_loss: 157.6413\n",
            "Epoch 991/1000\n",
            "1500/1500 [==============================] - 0s 106us/step - loss: 0.5082 - val_loss: 158.8371\n",
            "Epoch 992/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.3230 - val_loss: 158.0115\n",
            "Epoch 993/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.1845 - val_loss: 157.7188\n",
            "Epoch 994/1000\n",
            "1500/1500 [==============================] - 0s 109us/step - loss: 0.1436 - val_loss: 158.4679\n",
            "Epoch 995/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.2907 - val_loss: 158.4512\n",
            "Epoch 996/1000\n",
            "1500/1500 [==============================] - 0s 114us/step - loss: 0.1782 - val_loss: 159.1919\n",
            "Epoch 997/1000\n",
            "1500/1500 [==============================] - 0s 103us/step - loss: 0.6219 - val_loss: 159.8975\n",
            "Epoch 998/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.3058 - val_loss: 158.9687\n",
            "Epoch 999/1000\n",
            "1500/1500 [==============================] - 0s 105us/step - loss: 0.5151 - val_loss: 159.6788\n",
            "Epoch 1000/1000\n",
            "1500/1500 [==============================] - 0s 107us/step - loss: 0.3947 - val_loss: 159.0716\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsJkewV6upFV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "41a86b71-8f17-4296-c75b-7e3cd4005f76"
      },
      "source": [
        "# 5. 학습과정 살펴보기\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.ylim(0.0, 300.0)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWWbMEl7u5uW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cfa983c6-b1a9-47fc-8662-89d6a828432f"
      },
      "source": [
        "# 7. 모델 평가하기\n",
        "score = model.evaluate(x_test, y_test, batch_size=32)\n",
        "print(score)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 0s 262us/step\n",
            "236.95523315429688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMSuTWfru_Ak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "e6a0ad16-3da0-4e40-eecf-7c1ffad8e9a7"
      },
      "source": [
        "# 8. 모델 사용하기\n",
        "yhat_test = model.predict(x_test, batch_size=32)\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt_row = 5\n",
        "plt_col = 5\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (10, 10)\n",
        "\n",
        "f, axarr = plt.subplots(plt_row, plt_col)\n",
        "\n",
        "for i in range(plt_row * plt_col):\n",
        "    sub_plt = axarr[i//plt_row, i%plt_col]\n",
        "    sub_plt.axis('off')\n",
        "    sub_plt.imshow(x_test[i].reshape(width, height))\n",
        "    sub_plt.set_title('R %d P %.1f' %(y_test[i][0], yhat_test[i][0]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNj6iiUOvhTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}